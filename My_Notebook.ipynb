{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "import os\r\n",
                "import textract\r\n",
                "import PyPDF2\r\n",
                "\r\n",
                "dir_list = os.listdir(r'D:/FINAL YEAR PROJECT/Resumes/NewTestData/')\r\n",
                "paths = r'D:/FINAL YEAR PROJECT/Resumes/NewTestData/'\r\n",
                "c = 0\r\n",
                "for i in dir_list:\r\n",
                "    c = c + 1\r\n",
                "    if c == 5000:\r\n",
                "        break\r\n",
                "    pfinal = os.path.join(paths, i)\r\n",
                "\r\n",
                "#def extract_text_from_pdf(file):\r\n",
                "    '''Opens and reads in a PDF file from path'''\r\n",
                "\r\n",
                "    if i.endswith('.pdf'):\r\n",
                "        fileReader = PyPDF2.PdfFileReader(open(pfinal,'rb'))\r\n",
                "        page_count = fileReader.getNumPages()\r\n",
                "        text = [fileReader.getPage(i).extractText() for i in range(page_count)]\r\n",
                "    \r\n",
                "    #return str(text).replace(\"\\\\n\", \"\")\r\n",
                "\r\n",
                "#def extract_text_from_word(file):\r\n",
                "    '''Opens en reads in a .doc or .docx file from path'''\r\n",
                "\r\n",
                "    if i.endswith('.doc'):\r\n",
                "        text = textract.process(pfinal).decode('utf-8')\r\n",
                "\r\n",
                "    \r\n",
                "        \r\n",
                "    \r\n",
                "    #return txt.replace('\\n', ' ').replace('\\t', ' ')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "from resume_parser import resumeparse # Library 1\r\n",
                "from pyresparser import ResumeParser #Library 2\r\n",
                "import spacy\r\n",
                "spacy.load('en_core_web_sm')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate [util.py:275]\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<spacy.lang.en.English at 0x21d2bc32288>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 2
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "import os\r\n",
                "res_list = []\r\n",
                "dir_list = os.listdir(r'D:/FINAL YEAR PROJECT/Resumes/NewTestData/')\r\n",
                "paths = r'D:/FINAL YEAR PROJECT/Resumes/NewTestData/'\r\n",
                "c = 0\r\n",
                "for i in dir_list:\r\n",
                "    c = c + 1\r\n",
                "    if c == 5000:\r\n",
                "        break\r\n",
                "    pfinal = os.path.join(paths, i)\r\n",
                "    data = resumeparse.read_file(pfinal)\r\n",
                "    res_list.append(data)"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'resumeparse' is not defined",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-7-b88433f61dce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresumeparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mres_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'resumeparse' is not defined"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "print(len(res_list))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "14\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "import pandas as pd\r\n",
                "df= pd.DataFrame(res_list)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "df"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>email</th>\n",
                            "      <th>phone</th>\n",
                            "      <th>name</th>\n",
                            "      <th>total_exp</th>\n",
                            "      <th>university</th>\n",
                            "      <th>designition</th>\n",
                            "      <th>degree</th>\n",
                            "      <th>skills</th>\n",
                            "      <th>Companies worked at</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>:mikewanaswa@gmail.co</td>\n",
                            "      <td>2285993</td>\n",
                            "      <td>Personal Information</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[inoorero university]</td>\n",
                            "      <td>[installer, associate, technician, field engin...</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[(WIMAX,  FIBER,  MICROWAVES and Wi-Fi) for, S...</td>\n",
                            "      <td>[Cisco]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>shub.pandey7@yahoo.in</td>\n",
                            "      <td>+91-8765599273</td>\n",
                            "      <td>Curriculum Vitae</td>\n",
                            "      <td>8</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[development engineer, autocad, summer interns...</td>\n",
                            "      <td>[Bachelor in Mechanical]</td>\n",
                            "      <td>[:,  English,  Hindi, Social Responsibility:...</td>\n",
                            "      <td>[2D]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>ardraprasad93@gmail.com</td>\n",
                            "      <td>9891423551</td>\n",
                            "      <td>Curriculam Vitae</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[institute of science and technology]</td>\n",
                            "      <td>[entry level, autocad]</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[ AutoCAD 2D,  STAAD Pro.,  Programming lan...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>satyamce@gmail.com</td>\n",
                            "      <td>+918375887854</td>\n",
                            "      <td>SATYAM RICHHARIYA</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[Known English,  Hindi, Residential Address WZ...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>e-Mail:salman.ali19@gmail.com</td>\n",
                            "      <td>(+91)7503729071</td>\n",
                            "      <td>MOHAMMAD SALMAN</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[autocad, student]</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[Known : English,  Hindi., Alternate E-Mail : ...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>viren0312@gmail.com</td>\n",
                            "      <td>9909198882</td>\n",
                            "      <td>VIREN V.</td>\n",
                            "      <td>7</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[product specialist, partner, service represen...</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[rate contracts, distributors, clinic, working...</td>\n",
                            "      <td>[EMPLOYER, INDIA Level EMPLOYER – MsGlobus Rem...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>shub.pandey7@yahoo.in</td>\n",
                            "      <td>+91-8765599273</td>\n",
                            "      <td>Curriculum Vitae</td>\n",
                            "      <td>8</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[development engineer, autocad, summer interns...</td>\n",
                            "      <td>[Bachelor in Mechanical]</td>\n",
                            "      <td>[:,  English,  Hindi, Social Responsibility:...</td>\n",
                            "      <td>[2D]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>Email:alamdar1710@gmail.com</td>\n",
                            "      <td>+91 8976297830</td>\n",
                            "      <td>Email:alamdar1710@gmail.com Cell</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[quality control, quality control inspector, c...</td>\n",
                            "      <td>[Bachelors of Engineering in Mechanical]</td>\n",
                            "      <td>[Have exposure to relevant International Codes...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>ranji90kumar@gmail.com</td>\n",
                            "      <td>9884895521</td>\n",
                            "      <td>Ranjith Kumar</td>\n",
                            "      <td>3</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[relationship manager, senior sales executive,...</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[known : Read write Speak, English English Eng...</td>\n",
                            "      <td>[Pelican Insurance Broking Pvt. ltd, FutuRisk ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>rmoumita03@gmail.com</td>\n",
                            "      <td>7874038946</td>\n",
                            "      <td>Moumita Roy</td>\n",
                            "      <td>0</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[account assistant]</td>\n",
                            "      <td>[MBA, B.Com]</td>\n",
                            "      <td>[reporting, designation, word, ltd, debtors, b...</td>\n",
                            "      <td>[Orion Education Pvt Ltd August]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>10</th>\n",
                            "      <td>abiral.pandey88@gmail.com</td>\n",
                            "      <td>940-242-3303</td>\n",
                            "      <td>Abiral Pandey</td>\n",
                            "      <td>9</td>\n",
                            "      <td>[university of north texas]</td>\n",
                            "      <td>[full stack java developer, java developer, bu...</td>\n",
                            "      <td>[Bachelor of Computer Science]</td>\n",
                            "      <td>[:: Java/J2EE,  PL/SQL,  Unix Shell Scripts, J...</td>\n",
                            "      <td>[Oracle, oracle]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>11</th>\n",
                            "      <td>amirindersingh1234@gmail.com</td>\n",
                            "      <td>703-743-0795</td>\n",
                            "      <td>Amrinder Pelia</td>\n",
                            "      <td>13</td>\n",
                            "      <td>[michigan state university]</td>\n",
                            "      <td>[senior business analyst, business analyst, ri...</td>\n",
                            "      <td>[Bachelors in Applied Sciences and Engineering]</td>\n",
                            "      <td>[database, project plans, resource allocation,...</td>\n",
                            "      <td>[]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>12</th>\n",
                            "      <td>amulya.javadeveloper@gmail.com</td>\n",
                            "      <td>(515)309-1612</td>\n",
                            "      <td>AMULYA KOMATINENI</td>\n",
                            "      <td>9</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[locator, sql developer, full stack developer,...</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[:/API, Java 5/6/7/8,  Java/J2EE,  C,  JDBC,  ...</td>\n",
                            "      <td>[Amazon, Boss 6.x/7. x., XML Tools JAXB, YANA ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13</th>\n",
                            "      <td>Krish.java23@gmail.com</td>\n",
                            "      <td>681-888-2999</td>\n",
                            "      <td>Anil Krishna</td>\n",
                            "      <td>6</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>[j2ee developer, team member, locator, full st...</td>\n",
                            "      <td>[BACHELORS OF ENGINERRING IN ELECTRONICS AND C...</td>\n",
                            "      <td>[:, [bookmark: _GoBack]Java/J2EE,  JDK 1.6/1.7...</td>\n",
                            "      <td>[Amazon, RMI, Oracle, Oracle WebLogic 10g/11, ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                             email            phone  \\\n",
                            "0            :mikewanaswa@gmail.co          2285993   \n",
                            "1            shub.pandey7@yahoo.in   +91-8765599273   \n",
                            "2          ardraprasad93@gmail.com       9891423551   \n",
                            "3               satyamce@gmail.com    +918375887854   \n",
                            "4    e-Mail:salman.ali19@gmail.com  (+91)7503729071   \n",
                            "5              viren0312@gmail.com       9909198882   \n",
                            "6            shub.pandey7@yahoo.in   +91-8765599273   \n",
                            "7      Email:alamdar1710@gmail.com   +91 8976297830   \n",
                            "8           ranji90kumar@gmail.com       9884895521   \n",
                            "9             rmoumita03@gmail.com       7874038946   \n",
                            "10       abiral.pandey88@gmail.com     940-242-3303   \n",
                            "11    amirindersingh1234@gmail.com     703-743-0795   \n",
                            "12  amulya.javadeveloper@gmail.com    (515)309-1612   \n",
                            "13          Krish.java23@gmail.com     681-888-2999   \n",
                            "\n",
                            "                                name  total_exp  \\\n",
                            "0               Personal Information          0   \n",
                            "1                   Curriculum Vitae          8   \n",
                            "2                   Curriculam Vitae          0   \n",
                            "3                  SATYAM RICHHARIYA          0   \n",
                            "4                    MOHAMMAD SALMAN          0   \n",
                            "5                           VIREN V.          7   \n",
                            "6                   Curriculum Vitae          8   \n",
                            "7   Email:alamdar1710@gmail.com Cell          0   \n",
                            "8                      Ranjith Kumar          3   \n",
                            "9                        Moumita Roy          0   \n",
                            "10                     Abiral Pandey          9   \n",
                            "11                    Amrinder Pelia         13   \n",
                            "12                 AMULYA KOMATINENI          9   \n",
                            "13                      Anil Krishna          6   \n",
                            "\n",
                            "                               university  \\\n",
                            "0                   [inoorero university]   \n",
                            "1                                      []   \n",
                            "2   [institute of science and technology]   \n",
                            "3                                      []   \n",
                            "4                                      []   \n",
                            "5                                      []   \n",
                            "6                                      []   \n",
                            "7                                      []   \n",
                            "8                                      []   \n",
                            "9                                      []   \n",
                            "10            [university of north texas]   \n",
                            "11            [michigan state university]   \n",
                            "12                                     []   \n",
                            "13                                     []   \n",
                            "\n",
                            "                                          designition  \\\n",
                            "0   [installer, associate, technician, field engin...   \n",
                            "1   [development engineer, autocad, summer interns...   \n",
                            "2                              [entry level, autocad]   \n",
                            "3                                                  []   \n",
                            "4                                  [autocad, student]   \n",
                            "5   [product specialist, partner, service represen...   \n",
                            "6   [development engineer, autocad, summer interns...   \n",
                            "7   [quality control, quality control inspector, c...   \n",
                            "8   [relationship manager, senior sales executive,...   \n",
                            "9                                 [account assistant]   \n",
                            "10  [full stack java developer, java developer, bu...   \n",
                            "11  [senior business analyst, business analyst, ri...   \n",
                            "12  [locator, sql developer, full stack developer,...   \n",
                            "13  [j2ee developer, team member, locator, full st...   \n",
                            "\n",
                            "                                               degree  \\\n",
                            "0                                                  []   \n",
                            "1                            [Bachelor in Mechanical]   \n",
                            "2                                                  []   \n",
                            "3                                                  []   \n",
                            "4                                                  []   \n",
                            "5                                                  []   \n",
                            "6                            [Bachelor in Mechanical]   \n",
                            "7            [Bachelors of Engineering in Mechanical]   \n",
                            "8                                                  []   \n",
                            "9                                        [MBA, B.Com]   \n",
                            "10                     [Bachelor of Computer Science]   \n",
                            "11    [Bachelors in Applied Sciences and Engineering]   \n",
                            "12                                                 []   \n",
                            "13  [BACHELORS OF ENGINERRING IN ELECTRONICS AND C...   \n",
                            "\n",
                            "                                               skills  \\\n",
                            "0   [(WIMAX,  FIBER,  MICROWAVES and Wi-Fi) for, S...   \n",
                            "1   [:,  English,  Hindi, Social Responsibility:...   \n",
                            "2   [ AutoCAD 2D,  STAAD Pro.,  Programming lan...   \n",
                            "3   [Known English,  Hindi, Residential Address WZ...   \n",
                            "4   [Known : English,  Hindi., Alternate E-Mail : ...   \n",
                            "5   [rate contracts, distributors, clinic, working...   \n",
                            "6   [:,  English,  Hindi, Social Responsibility:...   \n",
                            "7   [Have exposure to relevant International Codes...   \n",
                            "8   [known : Read write Speak, English English Eng...   \n",
                            "9   [reporting, designation, word, ltd, debtors, b...   \n",
                            "10  [:: Java/J2EE,  PL/SQL,  Unix Shell Scripts, J...   \n",
                            "11  [database, project plans, resource allocation,...   \n",
                            "12  [:/API, Java 5/6/7/8,  Java/J2EE,  C,  JDBC,  ...   \n",
                            "13  [:, [bookmark: _GoBack]Java/J2EE,  JDK 1.6/1.7...   \n",
                            "\n",
                            "                                  Companies worked at  \n",
                            "0                                             [Cisco]  \n",
                            "1                                                [2D]  \n",
                            "2                                                  []  \n",
                            "3                                                  []  \n",
                            "4                                                  []  \n",
                            "5   [EMPLOYER, INDIA Level EMPLOYER – MsGlobus Rem...  \n",
                            "6                                                [2D]  \n",
                            "7                                                  []  \n",
                            "8   [Pelican Insurance Broking Pvt. ltd, FutuRisk ...  \n",
                            "9                    [Orion Education Pvt Ltd August]  \n",
                            "10                                   [Oracle, oracle]  \n",
                            "11                                                 []  \n",
                            "12  [Amazon, Boss 6.x/7. x., XML Tools JAXB, YANA ...  \n",
                            "13  [Amazon, RMI, Oracle, Oracle WebLogic 10g/11, ...  "
                        ]
                    },
                    "metadata": {},
                    "execution_count": 13
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import os\r\n",
                "import textract\r\n",
                "import PyPDF2\r\n",
                "\r\n",
                "dir_list = os.listdir(r'D:/FINAL YEAR PROJECT/Resumes/NewTestData/')\r\n",
                "resumes = r'D:/FINAL YEAR PROJECT/Resumes/NewTestData/'\r\n",
                "c = 0\r\n",
                "for i in dir_list:\r\n",
                "    c = c + 1\r\n",
                "    if c == 5000:\r\n",
                "        break\r\n",
                "    pfinal = os.path.join(paths, i)\r\n",
                "\r\n",
                "#def extract_text_from_pdf(file):\r\n",
                "    '''Opens and reads in a PDF file from path'''\r\n",
                "\r\n",
                "    if i.endswith('.pdf'):\r\n",
                "        fileReader = PyPDF2.PdfFileReader(open(pfinal,'rb'))\r\n",
                "        page_count = fileReader.getNumPages()\r\n",
                "        text = [fileReader.getPage(i).extractText() for i in range(page_count)]\r\n",
                "    \r\n",
                "    #return str(text).replace(\"\\\\n\", \"\")\r\n",
                "\r\n",
                "#def extract_text_from_word(file):\r\n",
                "    '''Opens en reads in a .doc or .docx file from path'''\r\n",
                "\r\n",
                "    if i.endswith('.doc'):\r\n",
                "        text = textract.process(pfinal).decode('utf-8')\r\n",
                "\r\n",
                "    \r\n",
                "        \r\n",
                "    \r\n",
                "    #return txt.replace('\\n', ' ').replace('\\t', ' ')"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'paths' is not defined",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-4-e3e694b62211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mpfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#def extract_text_from_pdf(file):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'paths' is not defined"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "import sys, fitz\r\n",
                "resume = \"D:/FINAL YEAR PROJECT/Resumes/NewTestData/Resume_Faith Catherine Otieno.pdf\"\r\n",
                "#fname = \"D:/FINAL YEAR PROJECT/ResumeRanking/Alice Clark CV.pdf\"\r\n",
                "doc = fitz.open(resume)\r\n",
                "resume_text = \"\"\r\n",
                "for page in doc:\r\n",
                "    resume_text = resume_text + str(page.getText())\r\n",
                "tx = \"\".join(resume_text.split(\"\\n\"))\r\n",
                "print(resume_text)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Faith Catherine Otieno\n",
                        "faithcathy12@gmail.com\n",
                        "0790517633\n",
                        "Nyeri, Kenya\n",
                        "EDUCATION\n",
                        "BSC.COMPUTER SCIENCE\n",
                        "Dedan Kimathi University of Technology\n",
                        "05/2018 -12/2021,\n",
                        "Nyeri,Kenya\n",
                        "HIGH SCHOOL\n",
                        "Moi Girls Isinya\n",
                        "02/2014 - 11/2017\n",
                        "Kajiado, Kenya\n",
                        "Grade\n",
                        "B+\n",
                        "TECHNICAL SKILLS\n",
                        "\n",
                        "WEB DEVELOPMENT\n",
                        "HTML, CSS, JAVASCRIPT, BOOTSTRAP, ANGULAR, DJANGO\n",
                        "\n",
                        "PYTHON\n",
                        "General python knowledge\n",
                        "DJANGO,\n",
                        "Learning to build REST APIs,\n",
                        "Learning Machine Learning.\n",
                        "\n",
                        "JAVA\n",
                        "General Java knowledge.\n",
                        "\n",
                        "Wordpress\n",
                        "Creating websites using wordpress.\n",
                        "SOFT SKILLS\n",
                        "\n",
                        "Good communication skills.\n",
                        "\n",
                        "Skills in creating innovative solutions.\n",
                        "\n",
                        "Team player\n",
                        "ACHIEVEMENTS\n",
                        "Completed the Web Specialist program 2020 for google Africa\n",
                        "Scholarships\n",
                        "(06/2020 - 10/2020)\n",
                        "The Google Africa Scholarship is a learning base program for individuals. I\n",
                        "personally went through the Web Specialist program where I was\n",
                        "introduced to web development. The program was in phases and only a\n",
                        "number of people proceeded to the next phase through qualifications in\n",
                        "quizzes and learning time. Through the program I was able to work in a\n",
                        "team in building a project EduShare that would be beneficial to the\n",
                        "community.\n",
                        "PROJECTS\n",
                        "Github Profile\n",
                        "https://github.com/faithkatherine\n",
                        "Weather App\n",
                        "https://myweather-fc2c3.web.app/\n",
                        "Edushare\n",
                        "(10/2020 - Present)\n",
                        "A community project we did with my GADS2020 team that connects\n",
                        "students and teachers around the world for online learning through sharing\n",
                        "notes, tutorials and quizzes\n",
                        "VOLUNTEER EXPERIENCE\n",
                        "Facilitating meet ups\n",
                        "Women Tech Makers Nyeri\n",
                        "Nyeri, Kenya\n",
                        "Tasks/Achievements\n",
                        "\n",
                        "Writing letters to secure venues\n",
                        "\n",
                        "Looking for speakers.\n",
                        "\n",
                        "Working with other volunteers to create a good experience for the\n",
                        "attendees.\n",
                        "Contact:\n",
                        "Grace Kahinga\n",
                        "+254798634840\n",
                        "Organizing Events\n",
                        "Google Developer Group Nyeri\n",
                        "Nyeri, Kenya\n",
                        "Tasks/Achievements\n",
                        "Participated in the event organization of DevFest Nyeri.\n",
                        "INTERESTS\n",
                        "\n",
                        "Interested in Web Development\n",
                        "\n",
                        "Aspiring Machine Learning Engineer\n",
                        "\n",
                        "Python\n",
                        "REFERENCES\n",
                        "Abednego Ng'ang'a\n",
                        "“Mentor”\n",
                        "Contact\n",
                        ":\n",
                        "abedy.nganga@gmail.com\n",
                        "-\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "job_description = open( \"D:/FINAL YEAR PROJECT/Resumes/JobDescriptions/java.txt\", \"r\")\r\n",
                "job_text = job_description.read()\r\n",
                "print(job_text)\r\n",
                "job_description.close()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Developing websites and software in Java\n",
                        "Developing and Programming the SMS Server in Java, testing and debugging the services for campaigns/promotions.\n",
                        "Maintain company website\n",
                        "Designing, developing, and administering MySql databases.\n",
                        "Integrating company systems with customer systems using various internet technologies\n",
                        "Working directly with clients to test, troubleshoot and recommend upgrades/improvements to new/existing systems.\n",
                        "Remotely troubleshoot, upgrade and fix problems in client systems using internet technologies\n",
                        "Design, develop and troubleshoot systems/solutions for clients and staff using various technologies to meet customer requirements.\n",
                        "Qualifications\n",
                        "Strong Java skills\n",
                        "Experience developing web applications in Java\n",
                        "Experience with Java development tools – Eclipse/Net-beans\n",
                        "Experience with JSP, JSF, Servlets, HTML5, CSS, JavaScript\n",
                        "Experience with MySQL\n",
                        "Experience with the full lifecycle of web development projects\n",
                        "Familiarity with Scrum (Agile) development methodology is a plus\n",
                        "Experience with Linux is a plus\n",
                        "Experience with PrimeFaces will be an added advantage\n",
                        "A proactive approach and an ability to work independently with little or no supervision\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "my_list = [resume_text, job_text]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "from sklearn.feature_extraction.text import CountVectorizer\r\n",
                "cv = CountVectorizer()\r\n",
                "count_matrix = cv.fit_transform(my_list)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "from sklearn.metrics.pairwise import cosine_similarity\r\n",
                "\r\n",
                "#Print the similarity scores\r\n",
                "print(\"\\nSimilarity Scores:\")\r\n",
                "print(cosine_similarity(count_matrix))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Similarity Scores:\n",
                        "[[1.         0.35713015]\n",
                        " [0.35713015 1.        ]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\r\n",
                "matchPercentage = round(matchPercentage, 2) # round to two decimal\r\n",
                "print(\"Your resume matches about \"+ str(matchPercentage)+ \"% of the job description.\")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Your resume matches about 35.71% of the job description.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "import textract\r\n",
                "resume = \"D:/FINAL YEAR PROJECT/Resumes/archive/Rao_Java.docx\"\r\n",
                "\r\n",
                "resume_text = textract.process(resume).decode('utf-8')\r\n",
                "print(resume_text)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "7\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Rao\n",
                        "\n",
                        "raojavadev7@gmail.com\n",
                        "\n",
                        "201-701-3757\n",
                        "\n",
                        "\n",
                        "\n",
                        "OBJECTIVE\n",
                        "\n",
                        "Had 8 years of IT experience in all phases of Software Development Life Cycle (SDLC) such as Planning, Analysis, Design, Implementation, Testing and Maintenance of Web Based, Client-Server, Dev-ops tools, Software Configuration and Build/Release Management and N-tier Architectures in domains like Insurance, Healthcare and Finance. I had a wide knowledge and proven experience in web development and maintenance. I am self-starter, quick learner and capable of working independently to achieve milestones and deadlines. I am adept at prioritizing, tracking and completing tasks to accomplish project goals.\n",
                        "\n",
                        "\n",
                        "\n",
                        "PROFESSIONAL SUMMARY\n",
                        "\n",
                        "\tExperience in providing technical solutions for business applications in development, designing, testing, building frameworks and implementing web-based Client-Server and Middleware multi-tier distributed environments using Java, J2EE.\n",
                        "\n",
                        "\tExperience in implementation of Web-based and Stand alone applications using concepts of Object Oriented Design (OOD), Object Oriented Analysis (OOA),Object Oriented Programming (OOP).\n",
                        "\n",
                        "\tHands on experience with various application design patterns like MVC, MVVC, MVP and GWT.\n",
                        "\n",
                        "\tDesigned and developed software applications using Java, Multithreading, Servlet, AngularJS, Bootstrap 3, JSP, JSTL, HTML, JavaScript, Ext JS, Groovy, Grails, EJB, JMS, XML, XSL, JSF, Ajax, JQuery, Adobe Flex 3, GWT, ADF etc.\n",
                        "\n",
                        "\tUsed Angular 2, TypeScript, Webpack, ES6 Features to develop the application. \n",
                        "\n",
                        "\tTurn mockups and design into pages complete with HTML/HTML5, CSS/CSS3, JavaScript and Angular2.\n",
                        "\n",
                        "\tExperience with Java 1.8 features such as Lambda Expressions for making anonymous inline function calls by using functional Interfaces which makes code readable and concise. \n",
                        "\n",
                        "\tWorked with Java 1.8 Streams API and parallel Streams API for enabling parallel processing of collections in distributed environment.\n",
                        "\n",
                        "\tHands on Experience in developing and designing the Micro Services using REST framework and Spring Boot. \n",
                        "\n",
                        "\tHands on Experience in designing and implementing AWS Solutions using EC2, S3, EBS, Elastic Load balancer (ELB), VPC, Lambda. \n",
                        "\n",
                        "\tUtilized AWS EC2 instances for application installation and preferred S3 buckets for the storage.\n",
                        "\n",
                        "\tExpertise in developing the Web-Based application by implementation of frameworks like Struts (Struts, Tag Libraries and Struts custom validation rules, Tiles), Spring (Spring MVC, Spring Web Flow, Spring IOC, Spring AOP, Spring Security, Spring Boot, Spring Data, Spring Batch), AJAX frameworks (Rich Faces, My Faces) and ORM frameworks like Hibernate and Mybatis.\n",
                        "\n",
                        "\tExpertise in implementing Web Services, related technologies & frame works: WSDL, SOAP, REST, JAX-WS, JAXB, JAX-RPC, AXIS and Jersey, SOAP UI and producing client utilizing Eclipse for Web Services consumption.\n",
                        "\n",
                        "\tDiverse experience utilizing tools in N-tier and Micro services architecture applications using Spring Boot, Spring Cloud config, Netflix OSS components(Eureka, Zuul, Hystrix), Pivotal Cloud Foundry, AWS, Rabbitmq, Kafka, Zookeeper, Cassandra, MySQL, Restful Web Services.\n",
                        "\n",
                        "\tHands on Experience in core java concepts like Collection Framework, Multi-threading, Generics, Annotations, Serialization, Thread pools, JavaBeans, Externalization\n",
                        "\n",
                        "\tExperienced in XML technologies like DTD, XSD, XSLT and parses like DOM, SAX and JAXB.\n",
                        "\n",
                        "\tHands on Experience at writing composite SQL queries, procedures, Triggers and stored procedures in various databases such as MySQL, Oracle and Cassandra.\n",
                        "\n",
                        "\tMade the integration of data in several applications in favor JSON documents with dynamic schemas using MongoDB (NoSQL) database. \n",
                        "\n",
                        "\tWorked on Node.js and MongoDB data store procedures to satisfy various business requirements of the application.\n",
                        "\n",
                        "\tExperienced in Middleware persistence framework like Hibernate/JPA for mapping Java classes with database and utilizing Hibernate Query Language (HQL).\n",
                        "\n",
                        "\tInstallation and configuration of Active MQ, Open MQ, IBM MQ Series and caching software like Oracle Coherence, Redis, Memcached and IBM ExtremeScale.\n",
                        "\n",
                        "\tExperienced in managing the security part of the application using technologies related to SSO.\n",
                        "\n",
                        "\tSingle sign-on (SSO) and multi-factor authentication with this property a user logs in with a single ID and password to gain access to a connected system or systems without using different usernames or passwords, or in some configurations seamlessly sign on at each system.\n",
                        "\n",
                        "\tInvolved in Authorization, Authentications & SSO using LDAP & AD.\n",
                        "\n",
                        "\tExperience in configuring and deploying the applications on application servers like WebSphere, Weblogic, JBoss and Glassfish.\n",
                        "\n",
                        "\tExpertise in performing the unit testing using JUnit, integration and deploying the applications using tools such as ANT and Maven, debugging through log4j.\n",
                        "\n",
                        "\tExperienced in developing Automation Scripts using Selenium Web-driver\n",
                        "\n",
                        "\tExperienced in JMS over messaging to exchange the information in more reliable and asynchronous way in enterprise Applications. Used Apache Active MQ and Apache Camel providers.\n",
                        "\n",
                        "\tActively involved in the DevOps streamlining process through Jenkins CI and CD Release Automation.\n",
                        "\n",
                        "\tStrong working experience in Cloud technologies like Pivotal Cloud Foundry (PCF), spring boot, Spring Cloud Config Server (SCCS), Jersey in spring boot, Service Registry (Eureka) on new development project as well as migration to traditional project on Cloud.\n",
                        "\n",
                        "\tExperience in implementing security models OAUTH2 and SAML for authentication/authorization using Spring Security and IAM Cloud Security. \n",
                        "\n",
                        "\tExperience in deploying the Application into Docker container and made easily accessible at runtime using Cloud Foundry and other cloud services like AWS, Netflix Eureka.\n",
                        "\n",
                        "\t Strong technical, administration, &mentoring knowledge in Apache Spark and Datastax Cassandra.\n",
                        "\n",
                        "\tExperienced in using streaming software like: Apache Storm, Kafka, Spark, RabbitMQ and integrating with APIs [Restful] with APIGEE and Layer7 \n",
                        "\n",
                        "\tExperienced in designing and developing asynchronous event based framework based on messaging infrastructure to process huge volume of messages using Solace queues, Apache Kafka, Storm and Zookeeper. Knowledge and experience in job work-flow scheduling and monitoring tools like Oozie and Zookeeper.\n",
                        "\n",
                        "\tKnowledge in testing web application vulnerabilities, OWASP is used as a guide in this review and testing process.\n",
                        "\n",
                        "\tExperienced in using JSON as the data exchange format and Swagger to provide the contracts between UI and middleware.\n",
                        "\n",
                        "Experience in writing shell scripting for deployment process and expertise in sharing files between Linux boxes and windows using the WinSCP, a secure FTP, SCP client for Microsoft Windows\n",
                        "\n",
                        "Experience in developing unit testing frameworks using JUnit, JMeter, DB Unit, Mockito and Groovy Spock based on test first or test driven methodology.\n",
                        "\n",
                        "Experienced in designing and implementing sw business rules using DROOLS framework. \n",
                        "\n",
                        "Experience in handling HP Fortify issues, Sonar, PMD.\n",
                        "\n",
                        "Extensive experience with Java complaint IDE’s like IBM RAD , IBM WSAD, Eclipse, Spring  STS and Intellij IDEA.\n",
                        "\n",
                        "\tWorked on production 0 for the client and business user application. Also supported critical business applications as L2 production support engineer.\n",
                        "\n",
                        "\t\n",
                        "\n",
                        "\tTECHNICAL SKILLS\n",
                        "\n",
                        "Languages\n",
                        "\n",
                        "C, C++, Java, J2EE, SQL, PL/SQL\n",
                        "\n",
                        "    J2EE Technologies\n",
                        "\n",
                        "JDBC, Servlets, JSP, JMS, Java Beans, JSTL, EJB, Struts, JNDI and JPA\n",
                        "\n",
                        "Web/XML Technologies\n",
                        "\n",
                        "HTML5, CSS3, JavaScript, JQuery, Ajax, AngularJs, Node JS, XML, XHTML XSD, XSL/XSLT, SAX/DOM, JSON.\n",
                        "\n",
                        "Tools & Framework\n",
                        "\n",
                        "Struts, Hibernate, Spring, Spring Boot , Spring Batch, Spring Security, Log4J, Jasper reports, SOA, SOAPUI, Apache Camel, Selenium and Cucumber.\n",
                        "\n",
                        "Web Services\n",
                        "\n",
                        "SOAP, Restful, UDDI, WSDL, JAX-RPC, JAX-RS JAX-WS, JAX-B, Apache Axis2, Apache CFX, JMS, AWS, Micro Services.\n",
                        "\n",
                        "Web/App Servers\n",
                        "\n",
                        "WebSphere, Apache Tomcat, WebLogic, JBoss.\n",
                        "\n",
                        "Continuous Integration\n",
                        "\n",
                        "Hudson, Jenkins.\n",
                        "\n",
                        "Database\n",
                        "\n",
                        "Oracle, SQL-Server, MySQL, NoSQL like Mongo DB \n",
                        "\n",
                        "Development Tools\n",
                        "\n",
                        "Eclipse, RAD, Spring Tool Suite (STS), IntelliJ\n",
                        "\n",
                        "O-R mapping\n",
                        "\n",
                        "\tHibernate, JPA, Mybatis\t\n",
                        "\n",
                        "Testing Tools/ Others\n",
                        "\n",
                        "JUnit, SoapUI, Putty, JIRA, Jenkins\n",
                        "\n",
                        "Version Control\n",
                        "\n",
                        "GIT, CVS, SVN, Rational clear case.\n",
                        "\n",
                        "Platforms\n",
                        "\n",
                        "Windows, UNIX/LINUX.\n",
                        "\n",
                        "Cloud Technologies\n",
                        "\n",
                        "AWS EC2, S3, Cloud formation, Netflix Eureka.\n",
                        "\n",
                        "PROFESSIONAL EXPERIENCE\n",
                        "\n",
                        "\n",
                        "\n",
                        "Client: Express Scripts\t\t\t\t\t\t\t\t                          Jan'17-Till date\n",
                        "\n",
                        "Location: Franklin lakes, NJ\n",
                        "\n",
                        "Role: Full Stack Developer\n",
                        "\n",
                        "\n",
                        "\n",
                        "Description: The Health Evaluation System is developed for the doctors who can use the system and give the details to the patients by the printout. This system will have all the information regarding the health related issues. Using this system doctor will get all the types of medicines for any type of health issues. The system will store all the information regarding health issues and their medications for different ages.\n",
                        "\n",
                        "\n",
                        "\n",
                        "\tRoles & Responsibilities:\n",
                        "\n",
                        "Involved in analysis, specification, design, and implementation and testing phases of Software Development Life Cycle (SDLC) and used agile methodology (SCRUM) for developing application.\n",
                        "\n",
                        "Upgraded existing UI with HTML5, CSS3, JavaScript, Ext Js and Bootstrap with Angular interaction.\n",
                        "\n",
                        "Used Angular 2.0 for Router to build single page applications for navigation through the different status and multiple modals. \n",
                        "\n",
                        "Used Angular 2.0 forms like Template Driven forms and Modern Driven (Reactive) forms to perform form validations both on server and client side.\n",
                        "\n",
                        "Used JSP, JQuery, AJAX and JSON for implementing presentation layer as well as MAVEN and Node Js server for deploying EAR files.\n",
                        "\n",
                        "Used Java 1.8 features like stream API and Lambda expressions.\n",
                        "\n",
                        "Maintained Interface compatibility and concurrency in the project using Java 1.8 new features like default, static methods and Concurrency API.\n",
                        "\n",
                        "Developed various helper classes needed following Core Java multi-threaded programming and Collection classes.\n",
                        "\n",
                        "Involved in migrating monolithic application in Microservice Architecture and Developed Micro-services using Pivotal Cloud Foundry platform build upon Spring Boot Services.\n",
                        "\n",
                        "Designed and developed Micro Services business components using Spring Boot.\n",
                        "\n",
                        "Worked on the REST Web Services and used Spring Framework and developed the Spring Features like Spring Core, Spring IOC, Spring AOP, Spring Data Access, and spring web test, Spring MVC, Spring DAO, Spring Boot, Spring Batch, Spring Security, and Spring Integration..\n",
                        "\n",
                        "Developed messaging module using Spring JMS, Apache Camel and Kafka.  \n",
                        "\n",
                        "Used Spring AOP Module to implement logging in the application to know the application status.\n",
                        "\n",
                        "Developed an API to write XML documents from a database. Utilized XML and XSL Transformation for dynamic web-content and database connectivity. \n",
                        "\n",
                        "Designed and developed third-party payment services, REST Web Services to offer users convenient payment methods using various APIs provided by various third-party payment processors based on OAuth 2.0 protocol.\n",
                        "\n",
                        "Developed the persistence layer using Hibernate Framework, created the POJO objects and mapped using Hibernate annotations and Transaction Management.\n",
                        "\n",
                        "Involved in multi-tiered J2EE design utilizing Spring Inversion of Control (IOC) and Hibernate.\n",
                        "\n",
                        "Involved in testing the applicable code using JUnit..\n",
                        "\n",
                        "Responsible for creation and execution of automation test scripts using Selenium, Webdriver.\n",
                        "\n",
                        "Written SQL Queries and stored procedures to interact with OracleDB.\n",
                        "\n",
                        "Configuring and maintaining the database PL/SQL. \n",
                        "\n",
                        "Worked with NoSQL Cassandra to store, retrieve, and update and manage all the details for Ethernet provisioning and customer order tracking.\n",
                        "\n",
                        "Developed custom Apache Spark batch job programs in Scala to create recommendations based on customer data.\n",
                        "\n",
                        "Used JIRA to assign, track, report and audit the issues in the application. Configured and customized logs using Log4J. \n",
                        "\n",
                        "Configured CICD pipeline by setting up Build, test, & deploy automation Jobs in Jenkins using Conditional Build steps pipeline by integrating Jenkins, Maven and Artifactory.\n",
                        "\n",
                        "Installed, configured SonarQube and continuously integrated the issues.\n",
                        "\n",
                        "Employed fail safe and circuit breaker patterns for the first time in Client's email applications using Hystrix and Hystrix Dashboard in Spring Boot Micro Service Applications. \n",
                        "\n",
                        "Implemented Single Sign On (SSO) to define the user roles and access\n",
                        "\n",
                        "Deployed the Application into Docker container and made easily accessible at runtime using Cloud Foundry and other cloud services like AWS, Netflix Eureka. \n",
                        "\n",
                        "Responsible for creating an instance on Amazon EC2 (AWS) and deployed the application on it and responsible for maintaining and expanding our AWS infrastructure using AWS (EC2/EBS).\n",
                        "\n",
                        "Utilized Amazon Web Services (AWS) EC2 to deploy Docker containers.\n",
                        "\n",
                        "Responsible to maintain the networking from AWS cloud back to On-Primary connectivity and no direct internet access from AWS cloud VPC to the rest of the world (Internet). \n",
                        "\n",
                        "Installing and configuring the applications like docker tool and kubernetes for the orchestration purpose. \n",
                        "\n",
                        " Using Chef deployed and configured Elastic search for log analytics, full text search, application monitoring in integration with AWS Lambda and CloudWatch. \n",
                        "\n",
                        "Created dynamic routing/load balancing capability enabling large application scaling for high availability.\n",
                        "\n",
                        "\n",
                        "\n",
                        "Environment: Agile(SCRUM), HTML5, CSS3, Bootstrap, JavaScript, JQuery, Ajax, AngularJs, AWS, Micro Services, Spring MVC, Hibernate, Spring, Oracle, Spring Batch, Spring Boot, Spring Security, JSON, XML, GIT, JUnit, Maven, JMS, Apache Tomcat, WebSphere, Rest Restful, JAX-RS, Log4J, SOA, JIRA, Jenkins.\n",
                        "\n",
                        "\n",
                        "\n",
                        "Client: \tBCBS\t\t\t\t\t                                                                                  Sep’15 – Dec'16\n",
                        "\n",
                        "Location: Dallas, TX\n",
                        "\n",
                        "Role: Full Stack Java Developer\n",
                        "\n",
                        "Description: Blue Cross and Blue Shield is an insurance company owned by its policyholders. This application was created to help individuals and families easily shop for and buy health insurance. BCBS offers a variety of insurance plans, as well as tools to help to help you choose the plan that’s right for you.\n",
                        "\n",
                        "Roles &Responsibilities:\n",
                        "\n",
                        "Involved in Daily Scrum (Agile) meetings, Sprint planning and estimation of the tasks for the user stories, participated in retrospective and presenting Demo at end of the sprint.\n",
                        "\n",
                        "Extensive experience on DevOps essential skills like continuous integration, continuous deployment, continuous delivery, supporting Build Pipelines Release management and cloud computing.\n",
                        "\n",
                        "Involved in the front end using JSP, HTML5, CSS3, JavaScript, and AJAX.        \n",
                        "\n",
                        "Used AngularJs to create views to hook up models to the DOM and synchronize data with server as a Single Page Application. \n",
                        "\n",
                        "Involved in development of Agent Verification System using Spring MVC framework. \n",
                        "\n",
                        "Used Spring AOP for logging, auditing and transaction management to distinguish business logic from the cross-cutting concerns. \n",
                        "\n",
                        "Implemented the application using Spring IOC, Spring MVC Framework, spring Batch and handled the security using Spring Security.\n",
                        "\n",
                        "Worked on Single Sign On application using LDAP directory service for secure authentication and assigning roles based on the login id.\n",
                        "\n",
                        "Implemented Web-Services to integrate between different applications components using Restful Web Services by using Jersey.\n",
                        "\n",
                        "Involved in identifying and implementation of different J2EE design patterns like Service Locator, Business Delegate, and DAO. \n",
                        "\n",
                        "Implemented business logic using Array list, Map and Sets of Collections API.  \n",
                        "\n",
                        "Developed Web Services component using XML, WSDL, and SOAP with DOM parser to transfer and transform data between applications.\n",
                        "\n",
                        "Used apache common digester to parse data from XML files and populate data into java beans. \n",
                        "\n",
                        "Created data model and generated Hibernate mappings and domain objects using Hibernate tools.\n",
                        "\n",
                        "Interfaced with the MySQL back-end database by integrating spring with Hibernate.\n",
                        "\n",
                        "Extensively used hibernate named queries, criteria queries, Hibernate Query Language (HQL) and Optimistic Locking and Caching to process the data from the database.\n",
                        "\n",
                        "Design and Coding the core framework using J2EE, Spring Boot, Jersey, Cloud technologies (SCCS, Eureka, encryption, security groups) on Pivotal Cloud Foundry (PCF) and the services with the integration points using J2EE, spring and Informatica Web Services (JAX RPC/JAX WS)\n",
                        "\n",
                        "Deployed and Monitored Micro Services using Pivotal Cloud Foundry, also Managed Domains and Routes with the Cloud Foundry.\n",
                        "\n",
                        "Performed deployment of applications on IBM WebSphere Application Server. \n",
                        "\n",
                        "Involved in implementing validations, exception handling. Worked with XML, XSLT for building up & transforming the xml files. \n",
                        "\n",
                        "Used IBM MQ and IBM Broker for transferring the data across multiple applications.\n",
                        "\n",
                        "Used IBM MQ as Queuing mechanism to send messages to clients and interact with other systems.\n",
                        "\n",
                        "Involved in testing the applicable code using JUnit. \n",
                        "\n",
                        "Used ClearCase for version control and ClearQuest for bug tracking and Used Apache ANT script for building the application with the build.xml. \n",
                        "\n",
                        "Used logging techniques provided by Log4j tool for efficient logging and debugging.\n",
                        "\n",
                        "Developed the application using Eclipse IDE and used its features for editing, debugging, compiling, formatting, and build automation. \n",
                        "\n",
                        "Environment:HTML5, CSS3, JavaScript, JQuery, AngularJs, DOJO, AJAX, JSP, Agile, Hibernate, Spring, Spring MVC, Servlets, REST, JAX-WS, Log4j, PL/SQL, Web Services, Weblogic Application Server, Oracle, JUnit, Log4j, JIRA, SVN.\n",
                        "\n",
                        "\n",
                        "\n",
                        "Client: Flag Star Bank\t\t\t\t\t\t\t\tOct'14 –Aug’15\n",
                        "\n",
                        "      Location: Troy, Michigan\n",
                        "\n",
                        "Role: Java Developer\n",
                        "\n",
                        "Description: Flagstar Bank is a Michigan based financial organization that offers services such as commercial and personal banking, online banking services, investment and loans. This application is developed to enhance online banking facility to the customer. Banking application has various modules for account maintenance, and email notification modules\n",
                        "\n",
                        "Roles &Responsibilities:\n",
                        "\n",
                        "Involved in SDLC requirements gathering, analysis, design, development and testing of application developed using agile methodology.\n",
                        "\n",
                        "Created user-friendly GUI interface and Web pages using HTML, Ajax and Java script.\n",
                        "\n",
                        "JVM tuning experience by changing to heap sizes according to the requirement.\n",
                        "\n",
                        " Experience in presentation layer for front-end of the application by using NodeJS boot strap programming and HTML pages. \n",
                        "\n",
                        "Used Spring MVC and Dependency Injection for handling presentation and business logic.\n",
                        "\n",
                        "To maintain loose coupling between layers published the business layer as services and injected the necessary dependent components using Spring IOC and published cross cutting concerns like Logging, User Interface exceptions, Transactions using Spring AOP. Integrated Spring DAO for data access using Hibernate.\n",
                        "\n",
                        "Used Spring Security for Authentication and Authorization of the application.\n",
                        "\n",
                        "Extensively used JSON to parse the data from server side to satisfy the business requirement.\n",
                        "\n",
                        "Used Apache Axis Service Engine for creating and deploying Web Service clients using SOAP, WSDL.\n",
                        "\n",
                        "Used Web Services for creating rate summary and used WSDL and SOAP messages for getting useful plans from different module.\n",
                        "\n",
                        "Implemented persistence framework using Hibernate& handled Transaction Management using the provided data source.\n",
                        "\n",
                        "Responsible for designing Hibernate mapping files based on business logic and Object relationships.\n",
                        "\n",
                        "Integrated spring and hibernate together and worked on developing backend components and services using Hibernate and spring.\n",
                        "\n",
                        "Extensively used HQL and SQL for querying databases. \n",
                        "\n",
                        "Developed Message Driven Bean for asynchronous sending Messages using JMS.\n",
                        "\n",
                        "Used Spring JMS module for lookup for the queues and MDBs for the listeners \n",
                        "\n",
                        "Established Database Connectivity using JDBC, Hibernate O/R mapping with Spring ORM for Oracle. \n",
                        "\n",
                        "Packaged and deployed the application in JBoss.\n",
                        "\n",
                        "Used Gradle tools for building and deploying the Web applications.\n",
                        "\n",
                        "Analysis and Bug fixing of the production problems and defects along with enhancements\n",
                        "\n",
                        "Implemented JUNIT test cases for unit testing and Suites for end to end testing.\n",
                        "\n",
                        "Used JIRA for tracking the Project Stories in Agile Methodology.\n",
                        "\n",
                        "Used Tortoise SVN to maintain the version of the files and took the responsibility to do the code merges from branch to trunk and creating new branch when new feature implementation starts.\n",
                        "\n",
                        "Environment: HTML, CSS, JavaScript, Bootstrap, AngularJs, JSON, XML, AJAX, JQuery, Struts, Hibernate, Spring MVC, SOAP,WSDL, HQL, SQL, JBoss, Oracle, JMS, JNDI, Maven, RMI, IntelliJ, UML, JIRA, JUNIT, Tortoise SVN, LINUX.\n",
                        "\n",
                        "\n",
                        "\n",
                        "Client: All Star                                                                                                 Nov'13 – Oct'14\n",
                        "\n",
                        "Location: Chicago, IL\n",
                        "\n",
                        "Role: JAVA Developer\n",
                        "\n",
                        "Description: All Star Insurance is a leading insurance company owned by its policyholders. An application is created to help individuals and families easily shop for, and buy health insurance which is used to handle insurance claims. ePAS is a secure, web-based insurance policy. Administration system allows authorized agents to quote and submit new policy applications, view policy statuses and submit policy endorsements. The system will guide the agent through the policy application and endorsement. Processes and automatically apply underwriting rules when submitting transactions.\t\n",
                        "\n",
                        "Roles &Responsibilities:\n",
                        "\n",
                        "Involved in all phases of the Software development life cycle (SDLC) using Agile Methodology.\n",
                        "\n",
                        "Developed User Interface using JSP, JSTL, HTML, CSS, Java Script, jQuery.\n",
                        "\n",
                        "\tUsed various jQuery UI controls and corresponding Event handlers.\n",
                        "\n",
                        "To maintain loose coupling between layers published the business layer as services and injected necessary dependent components using Spring IOC and published cross cutting concerns like Logging, User Interface exceptions, Transactions using Spring AOP. Integrated Spring DAO for data access using Hibernate. Used Spring Security for Authentication and Authorization of the application.\n",
                        "\n",
                        "Implemented persistence framework using Hibernate and Handled Transaction Management using the provided data source. Responsible for designing Hibernate mapping files based on business logic and Object relationships.\n",
                        "\n",
                        "Integrated Spring and Hibernate together and worked on developing backend components and services using Hibernate and spring. Established Database Connectivity using JDBC, Hibernate O/R mapping with Spring ORM for DB2. \n",
                        "\n",
                        "Worked on Hibernate in Data Access Layer for mapping the java objects to relational database and SQL queries to fetch the data, insert and update the data from the database. \n",
                        "\n",
                        "Implemented SOA architecture with Web Services using SOAP, WSDL and XML using Apache CXF framework and worked on parsing the XML files using DOM/SAX parsers.\n",
                        "\n",
                        "Extensively used JSON to parse the data from server side to satisfy the business requirement.\n",
                        "\n",
                        "Created Tables, Triggers, PL/SQL Stored Procedures, SQL queries, Joins and views for IBM DB2.\n",
                        "\n",
                        "Implemented SOAP based Web Services and used Soap UI for testing.\n",
                        "\n",
                        "Used Spring JMS module for lookup for the queues and MDBs for the listeners.\n",
                        "\n",
                        "Involved in Unit Testing of various modules by generating the Test Cases. Performed deployment of applications on WebSphere. Written LINUX shell scripts to identify user login information.\n",
                        "\n",
                        "Involved in day to day handling of JIRA issues (production issues at time) that involved data inconsistencies that required to be solved in very less time.\n",
                        "\n",
                        "Involved in Bug fixing of various modules that were raised by the testing teams in the application during the Integration testing phase.\n",
                        "\n",
                        "Environment: Java, J2EE, HTML, CSS, JavaScript, JQuery, JSP, JSTL, Spring, Hibernate, XML, XSD, SOAP UI, SOAP, WSDL, Log4j, JUnit, IBM DB2, WebSphere, SVN, Eclipse IDE, JIRA, Agile Methodology, Linux, Rational Rose and UML\n",
                        "\n",
                        "\n",
                        "\n",
                        "Client: Soft Pro Systems Ltd, Hyderabad, India\t\t                                                              June’11 – July’13\n",
                        "\n",
                        "Role: Java Developer\n",
                        "\n",
                        "Project: B2B solutions\n",
                        "\n",
                        "Description: This project is mainly an Intranet application meant for employees in the organization. They are Intranet mailing System, Chatting, File Transfer and Remote Login. This project is based on the client server methodology\n",
                        "\n",
                        "Roles &Responsibilities:\n",
                        "\n",
                        "Involved in Requirement Analysis, Design, Development and Testing of the risk workflow system.\n",
                        "\n",
                        "Involved in the implementation of design using vital phases of the Software development life cycle (SDLC) that includes Development, Testing, Implementation and Maintenance Support in WATER FALL methodology.\n",
                        "\n",
                        "Created user-friendly GUI interface and Web pages using JSP, HTML, CSS, AJAX, JavaScript and JQuery.\n",
                        "\n",
                        "Involved in component development using J2EE principles and used design patterns such as Singleton, Factory and Data Access Object (DAO) in the implementation of the application.\n",
                        "\n",
                        "Responsible for designing, coding and developed the application in J2EE using Struts MVC.\n",
                        "\n",
                        "Implemented Struts framework (Action & Controller classes) for dispatching request to appropriate classes. \n",
                        "\n",
                        "Used simple Struts Validation for validation of user input as per the business logic and initial data loading.\n",
                        "\n",
                        "Achieved synchronization of multiple threads through Multithreading and Exception Handling.\n",
                        "\n",
                        "Extensively used JSON to parse the data from server side to satisfy the business requirement.\n",
                        "\n",
                        "Developed Struts Action Forms, Action classes and performed action mapping using Struts. \n",
                        "\n",
                        "Developed RESTful and SOAP based Web Services to consume and produce data in XML and JSON.\n",
                        "\n",
                        "And also was involved in several custom validations Integration if Mybatis has reduced to create a JDBC connection and has eased the way of writing code. \n",
                        "\n",
                        "Written SQL queries, PL/SQL store procedures and Triggers to fetch and store data from the database.\n",
                        "\n",
                        "Used Log4J for application logging and notification tracing mechanisms.\n",
                        "\n",
                        "Developed the ANT scripts for preparing WAR files used to deploy J2EE components and deployment of the application was on Jetty.\n",
                        "\n",
                        "Prepared JUnit test cases and executed the test cases using JUnit. \n",
                        "\n",
                        "Involved in bug fixing during the System testing, Joint System testing and User acceptance testing.\n",
                        "\n",
                        "Used GIT to check-in and check-out and co-ordinate among team members for Version Controlling. Environment: Java, HTML, CSS, AJAX, jQuery, JavaScript, Struts, Web Services, SOAP, RESTful, JSON, XML, JDBC, SQL, MySQL, ANT, Eclipse, JIRA, GIT, Jetty and UNIX.\n",
                        "\n",
                        "\n",
                        "\n",
                        "Client: Info Tech                                                                                                                        May'09 – June’11\n",
                        "\n",
                        "\tLocation: Hyderabad, India\t\n",
                        "\n",
                        "Role: Jr. JAVA Developer\n",
                        "\n",
                        "Description: This is an Intranet application for shopping online within the community. The member of the community sitting at his home or office can shop different items belonging to different categories like Stationary, Electronic Goods, Apparel, Furniture, Vehicles, Home need appliances etc. in the store belonging to that community. The mode of payment is through their membership Card. An Updated record is delivered every month to the concerned member so those dues may be deducted from his membership account. Adequate security features were incorporated into the Project. Another record maintains stock update.\n",
                        "\n",
                        "Roles &Responsibilities:\n",
                        "\n",
                        "Involved in understanding and analyzing the requirements of the project. Followed Waterfall Methodology to implement the project. Used Java JDK features to implement the functionalities.\n",
                        "\n",
                        "Designed and developed the User Interface using HTML, JavaScript, AJAX and CSS.\n",
                        "\n",
                        "\tImplemented Struts MVC design pattern and front controller pattern and used for back-end.\n",
                        "\n",
                        "\tDeveloped Action Class components for performing business process execution and involved in configuration of struts configuration specific xml file.\n",
                        "\n",
                        "\tCreated and handled Custom-Exceptions that are related to business operations. Created child Threads to improve the performance by running some independent tasks at background.\n",
                        "\n",
                        "\tDeveloped Server-Side components for the business services for creating Items, BOM, Sourcing Rules, and substitute.\n",
                        "\n",
                        "Used Log4j for logging purposes during the development of the application. Used JDBC to interact with the underlying MySQL Database.\n",
                        "\n",
                        "\tExtensively worked on SQL for writing complex queries in the business logic layer. \n",
                        "\n",
                        "\tDeployed Applications on Apache Tomcat Server and used CVS as the version control manager. \n",
                        "\n",
                        "Environment: Java, JDBC, JDK, Servlets, Struts, JSP, Hibernate, Java Mail API, AJAX, HTML, XML, ANT, Log4J, CVS, RAD, Putty, MySQL, Mantis, Apache Tomcat, Eclipse IDE, Waterfall Methodology.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "import nltk, re\r\n",
                "from word2number import w2n\r\n",
                "import pandas as pd\r\n",
                "\r\n",
                "information=[]\r\n",
                "inputString = ''\r\n",
                "tokens = []\r\n",
                "lines = []\r\n",
                "sentences = []\r\n",
                "max_weightage = 40;\r\n",
                "min_variance = 5\r\n",
                "\r\n",
                "text        = job_text\r\n",
                "document    = resume_text"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "      \r\n",
                "try:\r\n",
                "    # Try to get rid of special characters\r\n",
                "    try:\r\n",
                "        document = document.decode('ascii', 'ignore')\r\n",
                "    except:\r\n",
                "        #Pass as document not encoded\r\n",
                "        pass\r\n",
                "    # Newlines are one element of structure in the data\r\n",
                "    # Helps limit the context and breaks up the data as is intended in resumes - i.e., into points\r\n",
                "    lines = [el.strip() for el in re.split(\"\\r|\\n\",document) if len(el) > 0]  # Splitting on the basis of newlines \r\n",
                "    lines = [nltk.word_tokenize(el) for el in lines]    # Tokenize the individual lines\r\n",
                "    lines = [nltk.pos_tag(el) for el in lines]  # Tag them\r\n",
                "    # Below approach is slightly different because it splits sentences not just on the basis of newlines, but also full stops \r\n",
                "    # - (barring abbreviations etc.)\r\n",
                "    # But it fails miserably at predicting names, so currently using it only for tokenization of the whole document\r\n",
                "    sentences = nltk.sent_tokenize(document)    # Split/Tokenize into sentences (List of strings)\r\n",
                "    sentences = [nltk.word_tokenize(sent) for sent in sentences]    # Split/Tokenize sentences into words (List of lists of strings)\r\n",
                "    tokens = sentences\r\n",
                "    sentences = [nltk.pos_tag(sent) for sent in sentences]    # Tag the tokens - list of lists of tuples - each tuple is (<word>, <tag>)\r\n",
                "    # Next 4 lines convert tokens from a list of list of strings to a list of strings; basically stitches them together\r\n",
                "    dummy = []\r\n",
                "    for el in tokens:\r\n",
                "        dummy += el\r\n",
                "    tokens = dummy\r\n",
                "    # tokens - words extracted from the doc, lines - split only based on newlines (may have more than one sentence)\r\n",
                "    # sentences - split on the basis of rules of grammar\r\n",
                "    print(tokens) \r\n",
                "    print(lines)\r\n",
                "    print(sentences)\r\n",
                "except Exception as e:\r\n",
                "    print(e)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['Faith', 'Catherine', 'Otieno', 'faithcathy12', '@', 'gmail.com', '0790517633', 'Nyeri', ',', 'Kenya', 'EDUCATION', 'BSC.COMPUTER', 'SCIENCE', 'Dedan', 'Kimathi', 'University', 'of', 'Technology', '05/2018', '-12/2021', ',', 'Nyeri', ',', 'Kenya', 'HIGH', 'SCHOOL', 'Moi', 'Girls', 'Isinya', '02/2014', '-', '11/2017', 'Kajiado', ',', 'Kenya', 'Grade', 'B+', 'TECHNICAL', 'SKILLS', '\\uf0b7', 'WEB', 'DEVELOPMENT', 'HTML', ',', 'CSS', ',', 'JAVASCRIPT', ',', 'BOOTSTRAP', ',', 'ANGULAR', ',', 'DJANGO', '\\uf0b7', 'PYTHON', 'General', 'python', 'knowledge', 'DJANGO', ',', 'Learning', 'to', 'build', 'REST', 'APIs', ',', 'Learning', 'Machine', 'Learning', '.', '\\uf0b7', 'JAVA', 'General', 'Java', 'knowledge', '.', '\\uf0b7', 'Wordpress', 'Creating', 'websites', 'using', 'wordpress', '.', 'SOFT', 'SKILLS', '\\uf0b7', 'Good', 'communication', 'skills', '.', '\\uf0b7', 'Skills', 'in', 'creating', 'innovative', 'solutions', '.', '\\uf0b7', 'Team', 'player', 'ACHIEVEMENTS', 'Completed', 'the', 'Web', 'Specialist', 'program', '2020', 'for', 'google', 'Africa', 'Scholarships', '(', '06/2020', '-', '10/2020', ')', 'The', 'Google', 'Africa', 'Scholarship', 'is', 'a', 'learning', 'base', 'program', 'for', 'individuals', '.', 'I', 'personally', 'went', 'through', 'the', 'Web', 'Specialist', 'program', 'where', 'I', 'was', 'introduced', 'to', 'web', 'development', '.', 'The', 'program', 'was', 'in', 'phases', 'and', 'only', 'a', 'number', 'of', 'people', 'proceeded', 'to', 'the', 'next', 'phase', 'through', 'qualifications', 'in', 'quizzes', 'and', 'learning', 'time', '.', 'Through', 'the', 'program', 'I', 'was', 'able', 'to', 'work', 'in', 'a', 'team', 'in', 'building', 'a', 'project', 'EduShare', 'that', 'would', 'be', 'beneficial', 'to', 'the', 'community', '.', 'PROJECTS', 'Github', 'Profile', 'https', ':', '//github.com/faithkatherine', 'Weather', 'App', 'https', ':', '//myweather-fc2c3.web.app/', 'Edushare', '(', '10/2020', '-', 'Present', ')', 'A', 'community', 'project', 'we', 'did', 'with', 'my', 'GADS2020', 'team', 'that', 'connects', 'students', 'and', 'teachers', 'around', 'the', 'world', 'for', 'online', 'learning', 'through', 'sharing', 'notes', ',', 'tutorials', 'and', 'quizzes', 'VOLUNTEER', 'EXPERIENCE', 'Facilitating', 'meet', 'ups', 'Women', 'Tech', 'Makers', 'Nyeri', 'Nyeri', ',', 'Kenya', 'Tasks/Achievements', '\\uf0b7', 'Writing', 'letters', 'to', 'secure', 'venues', '\\uf0b7', 'Looking', 'for', 'speakers', '.', '\\uf0b7', 'Working', 'with', 'other', 'volunteers', 'to', 'create', 'a', 'good', 'experience', 'for', 'the', 'attendees', '.', 'Contact', ':', 'Grace', 'Kahinga', '+254798634840', 'Organizing', 'Events', 'Google', 'Developer', 'Group', 'Nyeri', 'Nyeri', ',', 'Kenya', 'Tasks/Achievements', 'Participated', 'in', 'the', 'event', 'organization', 'of', 'DevFest', 'Nyeri', '.', 'INTERESTS', '\\uf0b7', 'Interested', 'in', 'Web', 'Development', '\\uf0b7', 'Aspiring', 'Machine', 'Learning', 'Engineer', '\\uf0b7', 'Python', 'REFERENCES', 'Abednego', \"Ng'ang\", \"'\", 'a', '“', 'Mentor', '”', 'Contact', ':', 'abedy.nganga', '@', 'gmail.com', '-']\n",
                        "[[('Faith', 'NNP'), ('Catherine', 'NNP'), ('Otieno', 'NNP')], [('faithcathy12', 'NN'), ('@', 'CD'), ('gmail.com', 'NN')], [('0790517633', 'CD')], [('Nyeri', 'NNP'), (',', ','), ('Kenya', 'NNP')], [('EDUCATION', 'NN')], [('BSC.COMPUTER', 'NNP'), ('SCIENCE', 'NNP')], [('Dedan', 'NNP'), ('Kimathi', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Technology', 'NNP')], [('05/2018', 'CD'), ('-12/2021', 'NN'), (',', ',')], [('Nyeri', 'NNP'), (',', ','), ('Kenya', 'NNP')], [('HIGH', 'JJ'), ('SCHOOL', 'NNP')], [('Moi', 'NNP'), ('Girls', 'NNP'), ('Isinya', 'NNP')], [('02/2014', 'CD'), ('-', ':'), ('11/2017', 'CD')], [('Kajiado', 'NNP'), (',', ','), ('Kenya', 'NNP')], [('Grade', 'NN')], [('B+', 'NN')], [('TECHNICAL', 'NNP'), ('SKILLS', 'NNP')], [('\\uf0b7', 'NN')], [('WEB', 'NNP'), ('DEVELOPMENT', 'NNP')], [('HTML', 'NNP'), (',', ','), ('CSS', 'NNP'), (',', ','), ('JAVASCRIPT', 'NNP'), (',', ','), ('BOOTSTRAP', 'NNP'), (',', ','), ('ANGULAR', 'NNP'), (',', ','), ('DJANGO', 'NNP')], [('\\uf0b7', 'NN')], [('PYTHON', 'NN')], [('General', 'NNP'), ('python', 'NN'), ('knowledge', 'NN')], [('DJANGO', 'NNP'), (',', ',')], [('Learning', 'VBG'), ('to', 'TO'), ('build', 'VB'), ('REST', 'NNP'), ('APIs', 'NNP'), (',', ',')], [('Learning', 'VBG'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('.', '.')], [('\\uf0b7', 'NN')], [('JAVA', 'NN')], [('General', 'NNP'), ('Java', 'NNP'), ('knowledge', 'NN'), ('.', '.')], [('\\uf0b7', 'NN')], [('Wordpress', 'NN')], [('Creating', 'VBG'), ('websites', 'NNS'), ('using', 'VBG'), ('wordpress', 'NN'), ('.', '.')], [('SOFT', 'NNP'), ('SKILLS', 'NNP')], [('\\uf0b7', 'NN')], [('Good', 'JJ'), ('communication', 'NN'), ('skills', 'NNS'), ('.', '.')], [('\\uf0b7', 'NN')], [('Skills', 'NNS'), ('in', 'IN'), ('creating', 'VBG'), ('innovative', 'JJ'), ('solutions', 'NNS'), ('.', '.')], [('\\uf0b7', 'NN')], [('Team', 'NN'), ('player', 'NN')], [('ACHIEVEMENTS', 'NNS')], [('Completed', 'VBN'), ('the', 'DT'), ('Web', 'NNP'), ('Specialist', 'NNP'), ('program', 'NN'), ('2020', 'CD'), ('for', 'IN'), ('google', 'NN'), ('Africa', 'NNP')], [('Scholarships', 'NNS')], [('(', '('), ('06/2020', 'CD'), ('-', ':'), ('10/2020', 'CD'), (')', ')')], [('The', 'DT'), ('Google', 'NNP'), ('Africa', 'NNP'), ('Scholarship', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('learning', 'JJ'), ('base', 'NN'), ('program', 'NN'), ('for', 'IN'), ('individuals', 'NNS'), ('.', '.'), ('I', 'PRP')], [('personally', 'RB'), ('went', 'VBD'), ('through', 'IN'), ('the', 'DT'), ('Web', 'NNP'), ('Specialist', 'NNP'), ('program', 'NN'), ('where', 'WRB'), ('I', 'PRP'), ('was', 'VBD')], [('introduced', 'VBN'), ('to', 'TO'), ('web', 'VB'), ('development', 'NN'), ('.', '.'), ('The', 'DT'), ('program', 'NN'), ('was', 'VBD'), ('in', 'IN'), ('phases', 'NNS'), ('and', 'CC'), ('only', 'RB'), ('a', 'DT')], [('number', 'NN'), ('of', 'IN'), ('people', 'NNS'), ('proceeded', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('next', 'JJ'), ('phase', 'NN'), ('through', 'IN'), ('qualifications', 'NNS'), ('in', 'IN')], [('quizzes', 'NNS'), ('and', 'CC'), ('learning', 'JJ'), ('time', 'NN'), ('.', '.'), ('Through', 'IN'), ('the', 'DT'), ('program', 'NN'), ('I', 'PRP'), ('was', 'VBD'), ('able', 'JJ'), ('to', 'TO'), ('work', 'VB'), ('in', 'IN'), ('a', 'DT')], [('team', 'NN'), ('in', 'IN'), ('building', 'VBG'), ('a', 'DT'), ('project', 'NN'), ('EduShare', 'NNP'), ('that', 'WDT'), ('would', 'MD'), ('be', 'VB'), ('beneficial', 'JJ'), ('to', 'TO'), ('the', 'DT')], [('community', 'NN'), ('.', '.')], [('PROJECTS', 'NN')], [('Github', 'NNP'), ('Profile', 'NNP')], [('https', 'NN'), (':', ':'), ('//github.com/faithkatherine', 'NN')], [('Weather', 'NNP'), ('App', 'NNP')], [('https', 'NN'), (':', ':'), ('//myweather-fc2c3.web.app/', 'JJ')], [('Edushare', 'NN')], [('(', '('), ('10/2020', 'CD'), ('-', ':'), ('Present', 'NN'), (')', ')')], [('A', 'DT'), ('community', 'NN'), ('project', 'NN'), ('we', 'PRP'), ('did', 'VBD'), ('with', 'IN'), ('my', 'PRP$'), ('GADS2020', 'NNP'), ('team', 'NN'), ('that', 'WDT'), ('connects', 'NNS')], [('students', 'NNS'), ('and', 'CC'), ('teachers', 'NNS'), ('around', 'IN'), ('the', 'DT'), ('world', 'NN'), ('for', 'IN'), ('online', 'NN'), ('learning', 'NN'), ('through', 'IN'), ('sharing', 'VBG')], [('notes', 'NNS'), (',', ','), ('tutorials', 'NNS'), ('and', 'CC'), ('quizzes', 'NNS')], [('VOLUNTEER', 'NNP'), ('EXPERIENCE', 'NNP')], [('Facilitating', 'VBG'), ('meet', 'NN'), ('ups', 'NNS')], [('Women', 'NNS'), ('Tech', 'NNP'), ('Makers', 'NNPS'), ('Nyeri', 'NNP')], [('Nyeri', 'NNP'), (',', ','), ('Kenya', 'NNP')], [('Tasks/Achievements', 'NNS')], [('\\uf0b7', 'NN')], [('Writing', 'VBG'), ('letters', 'NNS'), ('to', 'TO'), ('secure', 'VB'), ('venues', 'NNS')], [('\\uf0b7', 'NN')], [('Looking', 'VBG'), ('for', 'IN'), ('speakers', 'NNS'), ('.', '.')], [('\\uf0b7', 'NN')], [('Working', 'VBG'), ('with', 'IN'), ('other', 'JJ'), ('volunteers', 'NNS'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('good', 'JJ'), ('experience', 'NN'), ('for', 'IN'), ('the', 'DT')], [('attendees', 'NNS'), ('.', '.')], [('Contact', 'NN'), (':', ':')], [('Grace', 'NNP'), ('Kahinga', 'NNP')], [('+254798634840', 'NN')], [('Organizing', 'VBG'), ('Events', 'NNS')], [('Google', 'NNP'), ('Developer', 'NNP'), ('Group', 'NNP'), ('Nyeri', 'NNP')], [('Nyeri', 'NNP'), (',', ','), ('Kenya', 'NNP')], [('Tasks/Achievements', 'NNS')], [('Participated', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('event', 'NN'), ('organization', 'NN'), ('of', 'IN'), ('DevFest', 'NNP'), ('Nyeri', 'NNP'), ('.', '.')], [('INTERESTS', 'NN')], [('\\uf0b7', 'NN')], [('Interested', 'JJ'), ('in', 'IN'), ('Web', 'NNP'), ('Development', 'NNP')], [('\\uf0b7', 'NN')], [('Aspiring', 'VBG'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Engineer', 'NNP')], [('\\uf0b7', 'NN')], [('Python', 'NN')], [('REFERENCES', 'NNS')], [('Abednego', 'NNP'), (\"Ng'ang\", 'NNP'), (\"'\", 'POS'), ('a', 'DT')], [('“', 'JJ'), ('Mentor', 'NNP'), ('”', 'NN')], [('Contact', 'NN')], [(':', ':')], [('abedy.nganga', 'NN'), ('@', 'CD'), ('gmail.com', 'NN')], [('-', ':')]]\n",
                        "[[('Faith', 'NNP'), ('Catherine', 'NNP'), ('Otieno', 'NNP'), ('faithcathy12', 'NN'), ('@', 'NNP'), ('gmail.com', 'VBZ'), ('0790517633', 'CD'), ('Nyeri', 'NNP'), (',', ','), ('Kenya', 'NNP'), ('EDUCATION', 'NNP'), ('BSC.COMPUTER', 'NNP'), ('SCIENCE', 'NNP'), ('Dedan', 'NNP'), ('Kimathi', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Technology', 'NNP'), ('05/2018', 'CD'), ('-12/2021', 'NNP'), (',', ','), ('Nyeri', 'NNP'), (',', ','), ('Kenya', 'NNP'), ('HIGH', 'NNP'), ('SCHOOL', 'NNP'), ('Moi', 'NNP'), ('Girls', 'NNP'), ('Isinya', 'NNP'), ('02/2014', 'CD'), ('-', ':'), ('11/2017', 'CD'), ('Kajiado', 'NNP'), (',', ','), ('Kenya', 'NNP'), ('Grade', 'NNP'), ('B+', 'NNP'), ('TECHNICAL', 'NNP'), ('SKILLS', 'NNP'), ('\\uf0b7', 'NNP'), ('WEB', 'NNP'), ('DEVELOPMENT', 'NNP'), ('HTML', 'NNP'), (',', ','), ('CSS', 'NNP'), (',', ','), ('JAVASCRIPT', 'NNP'), (',', ','), ('BOOTSTRAP', 'NNP'), (',', ','), ('ANGULAR', 'NNP'), (',', ','), ('DJANGO', 'NNP'), ('\\uf0b7', 'NNP'), ('PYTHON', 'NNP'), ('General', 'NNP'), ('python', 'NN'), ('knowledge', 'NN'), ('DJANGO', 'NNP'), (',', ','), ('Learning', 'NNP'), ('to', 'TO'), ('build', 'VB'), ('REST', 'NNP'), ('APIs', 'NNP'), (',', ','), ('Learning', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('.', '.')], [('\\uf0b7', 'NN'), ('JAVA', 'NNP'), ('General', 'NNP'), ('Java', 'NNP'), ('knowledge', 'NN'), ('.', '.')], [('\\uf0b7', 'JJ'), ('Wordpress', 'NNP'), ('Creating', 'NNP'), ('websites', 'VBZ'), ('using', 'VBG'), ('wordpress', 'NN'), ('.', '.')], [('SOFT', 'NNP'), ('SKILLS', 'NNP'), ('\\uf0b7', 'NNP'), ('Good', 'NNP'), ('communication', 'NN'), ('skills', 'NNS'), ('.', '.')], [('\\uf0b7', 'NN'), ('Skills', 'NNP'), ('in', 'IN'), ('creating', 'VBG'), ('innovative', 'JJ'), ('solutions', 'NNS'), ('.', '.')], [('\\uf0b7', 'NN'), ('Team', 'NNP'), ('player', 'NN'), ('ACHIEVEMENTS', 'NNP'), ('Completed', 'VBD'), ('the', 'DT'), ('Web', 'NNP'), ('Specialist', 'NNP'), ('program', 'NN'), ('2020', 'CD'), ('for', 'IN'), ('google', 'NN'), ('Africa', 'NNP'), ('Scholarships', 'NNP'), ('(', '('), ('06/2020', 'CD'), ('-', ':'), ('10/2020', 'CD'), (')', ')'), ('The', 'DT'), ('Google', 'NNP'), ('Africa', 'NNP'), ('Scholarship', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('learning', 'JJ'), ('base', 'NN'), ('program', 'NN'), ('for', 'IN'), ('individuals', 'NNS'), ('.', '.')], [('I', 'PRP'), ('personally', 'RB'), ('went', 'VBD'), ('through', 'IN'), ('the', 'DT'), ('Web', 'NNP'), ('Specialist', 'NNP'), ('program', 'NN'), ('where', 'WRB'), ('I', 'PRP'), ('was', 'VBD'), ('introduced', 'VBN'), ('to', 'TO'), ('web', 'VB'), ('development', 'NN'), ('.', '.')], [('The', 'DT'), ('program', 'NN'), ('was', 'VBD'), ('in', 'IN'), ('phases', 'NNS'), ('and', 'CC'), ('only', 'RB'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('people', 'NNS'), ('proceeded', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('next', 'JJ'), ('phase', 'NN'), ('through', 'IN'), ('qualifications', 'NNS'), ('in', 'IN'), ('quizzes', 'NNS'), ('and', 'CC'), ('learning', 'JJ'), ('time', 'NN'), ('.', '.')], [('Through', 'IN'), ('the', 'DT'), ('program', 'NN'), ('I', 'PRP'), ('was', 'VBD'), ('able', 'JJ'), ('to', 'TO'), ('work', 'VB'), ('in', 'IN'), ('a', 'DT'), ('team', 'NN'), ('in', 'IN'), ('building', 'VBG'), ('a', 'DT'), ('project', 'NN'), ('EduShare', 'NNP'), ('that', 'WDT'), ('would', 'MD'), ('be', 'VB'), ('beneficial', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('community', 'NN'), ('.', '.')], [('PROJECTS', 'NNP'), ('Github', 'NNP'), ('Profile', 'NNP'), ('https', 'NN'), (':', ':'), ('//github.com/faithkatherine', 'NN'), ('Weather', 'NNP'), ('App', 'NNP'), ('https', 'NN'), (':', ':'), ('//myweather-fc2c3.web.app/', 'JJ'), ('Edushare', 'NNP'), ('(', '('), ('10/2020', 'CD'), ('-', ':'), ('Present', 'NN'), (')', ')'), ('A', 'NNP'), ('community', 'NN'), ('project', 'NN'), ('we', 'PRP'), ('did', 'VBD'), ('with', 'IN'), ('my', 'PRP$'), ('GADS2020', 'NNP'), ('team', 'NN'), ('that', 'WDT'), ('connects', 'VBZ'), ('students', 'NNS'), ('and', 'CC'), ('teachers', 'NNS'), ('around', 'IN'), ('the', 'DT'), ('world', 'NN'), ('for', 'IN'), ('online', 'NN'), ('learning', 'NN'), ('through', 'IN'), ('sharing', 'VBG'), ('notes', 'NNS'), (',', ','), ('tutorials', 'NNS'), ('and', 'CC'), ('quizzes', 'NNS'), ('VOLUNTEER', 'NNP'), ('EXPERIENCE', 'NNP'), ('Facilitating', 'NNP'), ('meet', 'NN'), ('ups', 'JJ'), ('Women', 'NNP'), ('Tech', 'NNP'), ('Makers', 'NNP'), ('Nyeri', 'NNP'), ('Nyeri', 'NNP'), (',', ','), ('Kenya', 'NNP'), ('Tasks/Achievements', 'NNP'), ('\\uf0b7', 'NNP'), ('Writing', 'NNP'), ('letters', 'NNS'), ('to', 'TO'), ('secure', 'VB'), ('venues', 'NNS'), ('\\uf0b7', 'VB'), ('Looking', 'VBG'), ('for', 'IN'), ('speakers', 'NNS'), ('.', '.')], [('\\uf0b7', 'NNS'), ('Working', 'VBG'), ('with', 'IN'), ('other', 'JJ'), ('volunteers', 'NNS'), ('to', 'TO'), ('create', 'VB'), ('a', 'DT'), ('good', 'JJ'), ('experience', 'NN'), ('for', 'IN'), ('the', 'DT'), ('attendees', 'NNS'), ('.', '.')], [('Contact', 'NN'), (':', ':'), ('Grace', 'NNP'), ('Kahinga', 'NNP'), ('+254798634840', 'NNP'), ('Organizing', 'NNP'), ('Events', 'NNP'), ('Google', 'NNP'), ('Developer', 'NNP'), ('Group', 'NNP'), ('Nyeri', 'NNP'), ('Nyeri', 'NNP'), (',', ','), ('Kenya', 'NNP'), ('Tasks/Achievements', 'NNP'), ('Participated', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('event', 'NN'), ('organization', 'NN'), ('of', 'IN'), ('DevFest', 'NNP'), ('Nyeri', 'NNP'), ('.', '.')], [('INTERESTS', 'NNP'), ('\\uf0b7', 'NNP'), ('Interested', 'NNP'), ('in', 'IN'), ('Web', 'NNP'), ('Development', 'NNP'), ('\\uf0b7', 'NNP'), ('Aspiring', 'NNP'), ('Machine', 'NNP'), ('Learning', 'NNP'), ('Engineer', 'NNP'), ('\\uf0b7', 'NNP'), ('Python', 'NNP'), ('REFERENCES', 'NNP'), ('Abednego', 'NNP'), (\"Ng'ang\", 'NNP'), (\"'\", 'POS'), ('a', 'DT'), ('“', 'JJ'), ('Mentor', 'NNP'), ('”', 'NNP'), ('Contact', 'NNP'), (':', ':'), ('abedy.nganga', 'NN'), ('@', 'NNP'), ('gmail.com', 'NN'), ('-', ':')]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "expMatchStrings = ['experience', 'exp ', 'exp.', 'exp:','experience:']\r\n",
                "#TODO need to calculate months also\r\n",
                "yearStrings = ['yrs', 'years', 'yr']\r\n",
                "experience = []\r\n",
                "experience_df=pd.DataFrame(columns=('Type', 'Years', 'Months', 'Location'))\r\n",
                "try:\r\n",
                "    pos = 0\r\n",
                "    for sentence in lines:#find the index of the sentence where the degree is find and then analyse that sentence\r\n",
                "        pos = pos+1\r\n",
                "        sen=\" \".join([words[0].lower() for words in sentence]) #string of words in sentence\r\n",
                "        if any(re.search(x,sen) for x in expMatchStrings) and any(re.search(x,sen) for x in yearStrings):\r\n",
                "            sen_tokenised= nltk.word_tokenize(sen)\r\n",
                "            tagged = nltk.pos_tag(sen_tokenised)\r\n",
                "            entities = nltk.chunk.ne_chunk(tagged)\r\n",
                "            for subtree in entities.subtrees():\r\n",
                "                for leaf in subtree.leaves():\r\n",
                "                    if leaf[1]=='CD':\r\n",
                "                        if re.search('total',sen):\r\n",
                "                            expType = 1\r\n",
                "                        else: \r\n",
                "                            if re.search('overall',sen):\r\n",
                "                                expType = 2\r\n",
                "                            else:\r\n",
                "                                expType = 3\r\n",
                "                                \r\n",
                "                        expStr = leaf[0].strip('+').strip('\\x07')\r\n",
                "                        \r\n",
                "                        for match in (expMatchStrings+yearStrings):\r\n",
                "                            expStr = expStr.replace(match,\"\")\r\n",
                "                            \r\n",
                "                            #If expStr contains only digit\r\n",
                "                            try:\r\n",
                "                                years = float(expStr)\r\n",
                "                            except:\r\n",
                "                                try:\r\n",
                "                                    # If expStr is string which can be converted into number\r\n",
                "                                    years = w2n.word_to_num(expStr)\r\n",
                "                                except:\r\n",
                "                                    # try to remove all non-numeric characters from string except dot\r\n",
                "                                    non_decimal = re.compile(r'[^\\d.]+')\r\n",
                "                                    expStr=non_decimal.sub(\"\", expStr)\r\n",
                "                                    try:\r\n",
                "                                        years = float(expStr)\r\n",
                "                                    except Exception as e:\r\n",
                "                                        years = 0\r\n",
                "                                        print(e)\r\n",
                "                    \r\n",
                "                            if years>0 and years < 30:\r\n",
                "                                experience_df = experience_df.append({'Type': expType, 'Years': years, 'Months': 0, 'Location': pos},ignore_index=True)                                    \r\n",
                "                                print(experience_df)                                        \r\n",
                "    if not experience_df.empty:\r\n",
                "        #experience_df = experience_df.sort_values(['Type', 'Years','Location'], ascending=[True, False, True])\r\n",
                "        experience_df = experience_df.sort_values(['Type', 'Years'], ascending=[True, False])\r\n",
                "        experience = float(experience_df['Years'].iloc[0])\r\n",
                "        print(experience_df)\r\n",
                "    else:\r\n",
                "        experience = 0.0\r\n",
                "        print(experience)\r\n",
                "                \r\n",
                "except Exception as e:\r\n",
                "    print (e)\r\n",
                "    \r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0.0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "    def get_exp_weightage(self,jd_exp,resume_exp):\r\n",
                "        \r\n",
                "        score = 0\r\n",
                "        resume_exp = int(round(resume_exp))\r\n",
                "        #print(resume_exp)\r\n",
                "        if jd_exp.find(\"-\") == -1:\r\n",
                "            jd_exp = \"0-\"+jd_exp[:]\r\n",
                "            \r\n",
                "        min_jd_exp =  int(jd_exp[0])\r\n",
                "        max_jd_exp = int(jd_exp[2])\r\n",
                "        \r\n",
                "        if resume_exp == 0:\r\n",
                "            score = 0\r\n",
                "            \r\n",
                "        elif resume_exp > min_jd_exp:\r\n",
                "            if resume_exp > max_jd_exp:\r\n",
                "                score = self.max_weightage - (self.min_variance*(resume_exp-max_jd_exp))\r\n",
                "            else:\r\n",
                "                score = self.max_weightage\r\n",
                "                \r\n",
                "        else:\r\n",
                "            score = self.max_weightage - (self.min_variance*(min_jd_exp-resume_exp))\r\n",
                "            print(score)\r\n",
                "        \r\n",
                "        if score < 0:\r\n",
                "            score = 0\r\n",
                "            print(score)\r\n",
                "        \r\n",
                "        return score"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "import nltk, re\r\n",
                "from word2number import w2n\r\n",
                "import pandas as pd\r\n",
                "\r\n",
                "class ExtractExp:\r\n",
                "    \r\n",
                "    information=[]\r\n",
                "    inputString = ''\r\n",
                "    tokens = []\r\n",
                "    lines = []\r\n",
                "    sentences = []\r\n",
                "    max_weightage = 40;\r\n",
                "    min_variance = 5\r\n",
                "    \r\n",
                "    text        = job_text\r\n",
                "    document    = resume_text\r\n",
                "    #print(text)\r\n",
                "    #print(document)\r\n",
                "    \r\n",
                "    def get_features(self, text): \r\n",
                "        #TODO: Download below package only once\r\n",
                "        #nltk.download('punkt')\r\n",
                "        #nltk.download('averaged_perceptron_tagger')\r\n",
                "        #nltk.download('maxent_ne_chunker')\r\n",
                "        #nltk.download('words')\r\n",
                "       \r\n",
                "        self.preprocess_data(text)\r\n",
                "        self.tokenize(text)\r\n",
                "        return self.get_exp(text)\r\n",
                "            \r\n",
                "    def preprocess_data(self, document ):\r\n",
                "        \r\n",
                "        try:\r\n",
                "            # Try to get rid of special characters\r\n",
                "            try:\r\n",
                "                document = document.decode('ascii', 'ignore')\r\n",
                "            except:\r\n",
                "                #Pass as document not encoded\r\n",
                "                pass\r\n",
                "            # Newlines are one element of structure in the data\r\n",
                "            # Helps limit the context and breaks up the data as is intended in resumes - i.e., into points\r\n",
                "            lines = [el.strip() for el in re.split(\"\\r|\\n\",document) if len(el) > 0]  # Splitting on the basis of newlines \r\n",
                "            lines = [nltk.word_tokenize(el) for el in lines]    # Tokenize the individual lines\r\n",
                "            lines = [nltk.pos_tag(el) for el in lines]  # Tag them\r\n",
                "            # Below approach is slightly different because it splits sentences not just on the basis of newlines, but also full stops \r\n",
                "            # - (barring abbreviations etc.)\r\n",
                "            # But it fails miserably at predicting names, so currently using it only for tokenization of the whole document\r\n",
                "            sentences = nltk.sent_tokenize(document)    # Split/Tokenize into sentences (List of strings)\r\n",
                "            sentences = [nltk.word_tokenize(sent) for sent in sentences]    # Split/Tokenize sentences into words (List of lists of strings)\r\n",
                "            tokens = sentences\r\n",
                "            sentences = [nltk.pos_tag(sent) for sent in sentences]    # Tag the tokens - list of lists of tuples - each tuple is (<word>, <tag>)\r\n",
                "            # Next 4 lines convert tokens from a list of list of strings to a list of strings; basically stitches them together\r\n",
                "            dummy = []\r\n",
                "            for el in tokens:\r\n",
                "                dummy += el\r\n",
                "            tokens = dummy\r\n",
                "            # tokens - words extracted from the doc, lines - split only based on newlines (may have more than one sentence)\r\n",
                "            # sentences - split on the basis of rules of grammar\r\n",
                "            return tokens, lines, sentences\r\n",
                "        except Exception as e:\r\n",
                "            print(e)\r\n",
                "    \r\n",
                "    def tokenize(self, inputString):\r\n",
                "        try:\r\n",
                "            self.tokens, self.lines, self.sentences = self.preprocess_data(inputString)\r\n",
                "            return self.tokens, self.lines, self.sentences\r\n",
                "        except Exception as e:\r\n",
                "            print(e)\r\n",
                "    \r\n",
                "    def get_exp(self,inputString):\r\n",
                "        expMatchStrings = ['experience', 'exp ', 'exp.', 'exp:','experience:']\r\n",
                "        #TODO need to calculate months also\r\n",
                "        yearStrings = ['yrs', 'years', 'yr']\r\n",
                "        experience = []\r\n",
                "        experience_df=pd.DataFrame(columns=('Type', 'Years', 'Months', 'Location'))\r\n",
                "        try:\r\n",
                "            pos = 0\r\n",
                "            for sentence in self.lines:#find the index of the sentence where the degree is find and then analyse that sentence\r\n",
                "                pos = pos+1\r\n",
                "                sen=\" \".join([words[0].lower() for words in sentence]) #string of words in sentence\r\n",
                "                if any(re.search(x,sen) for x in expMatchStrings) and any(re.search(x,sen) for x in yearStrings):\r\n",
                "                    sen_tokenised= nltk.word_tokenize(sen)\r\n",
                "                    tagged = nltk.pos_tag(sen_tokenised)\r\n",
                "                    entities = nltk.chunk.ne_chunk(tagged)\r\n",
                "                    for subtree in entities.subtrees():\r\n",
                "                        for leaf in subtree.leaves():\r\n",
                "                            if leaf[1]=='CD':\r\n",
                "                                if re.search('total',sen):\r\n",
                "                                    expType = 1\r\n",
                "                                else: \r\n",
                "                                    if re.search('overall',sen):\r\n",
                "                                        expType = 2\r\n",
                "                                    else:\r\n",
                "                                        expType = 3\r\n",
                "                                        \r\n",
                "                                expStr = leaf[0].strip('+').strip('\\x07')\r\n",
                "                                \r\n",
                "                                for match in (expMatchStrings+yearStrings):\r\n",
                "                                    expStr = expStr.replace(match,\"\")\r\n",
                "                                    \r\n",
                "                                    #If expStr contains only digit\r\n",
                "                                    try:\r\n",
                "                                        years = float(expStr)\r\n",
                "                                    except:\r\n",
                "                                        try:\r\n",
                "                                            # If expStr is string which can be converted into number\r\n",
                "                                            years = w2n.word_to_num(expStr)\r\n",
                "                                        except:\r\n",
                "                                            # try to remove all non-numeric characters from string except dot\r\n",
                "                                            non_decimal = re.compile(r'[^\\d.]+')\r\n",
                "                                            expStr=non_decimal.sub(\"\", expStr)\r\n",
                "                                            try:\r\n",
                "                                                years = float(expStr)\r\n",
                "                                            except Exception as e:\r\n",
                "                                                years = 0\r\n",
                "                                                print(e)\r\n",
                "                            \r\n",
                "                                    if years>0 and years < 30:\r\n",
                "                                        experience_df = experience_df.append({'Type': expType, 'Years': years, 'Months': 0, 'Location': pos},ignore_index=True)                                    \r\n",
                "                                                                                \r\n",
                "            if not experience_df.empty:\r\n",
                "                #experience_df = experience_df.sort_values(['Type', 'Years','Location'], ascending=[True, False, True])\r\n",
                "                experience_df = experience_df.sort_values(['Type', 'Years'], ascending=[True, False])\r\n",
                "                experience = float(experience_df['Years'].iloc[0])\r\n",
                "            else:\r\n",
                "                experience = 0.0\r\n",
                "                        \r\n",
                "        except Exception as e: \r\n",
                "            print (e)\r\n",
                "            \r\n",
                "        return experience\r\n",
                "\r\n",
                "    def get_exp_weightage(self,jd_exp,resume_exp):\r\n",
                "        \r\n",
                "        score = 0\r\n",
                "        resume_exp = int(round(resume_exp))\r\n",
                "        #print(resume_exp)\r\n",
                "        if jd_exp.find(\"-\") == -1:\r\n",
                "            jd_exp = \"0-\"+jd_exp[:]\r\n",
                "            \r\n",
                "        min_jd_exp =  int(jd_exp[0])\r\n",
                "        max_jd_exp = int(jd_exp[2])\r\n",
                "        \r\n",
                "        if resume_exp == 0:\r\n",
                "            score = 0\r\n",
                "            \r\n",
                "        elif resume_exp > min_jd_exp:\r\n",
                "            if resume_exp > max_jd_exp:\r\n",
                "                score = self.max_weightage - (self.min_variance*(resume_exp-max_jd_exp))\r\n",
                "            else:\r\n",
                "                score = self.max_weightage\r\n",
                "                \r\n",
                "        else:\r\n",
                "            score = self.max_weightage - (self.min_variance*(min_jd_exp-resume_exp))\r\n",
                "            print(score)\r\n",
                "        \r\n",
                "        if score < 0:\r\n",
                "            score = 0\r\n",
                "        \r\n",
                "        return score "
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import re\r\n",
                "import json\r\n",
                "import logging\r\n",
                "import numpy as np\r\n",
                "from tqdm import trange\r\n",
                "import torch\r\n",
                "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\r\n",
                "from seqeval.metrics import classification_report\r\n",
                "from sklearn.metrics import confusion_matrix\r\n",
                "\r\n",
                "\r\n",
                "def convert_goldparse(dataturks_JSON_FilePath):\r\n",
                "    try:\r\n",
                "        training_data = []\r\n",
                "        lines = []\r\n",
                "        with open(dataturks_JSON_FilePath, 'r') as f:\r\n",
                "            lines = f.readlines()\r\n",
                "\r\n",
                "        for line in lines:\r\n",
                "            data = json.loads(line)\r\n",
                "            text = data['content'].replace(\"\\n\", \" \")\r\n",
                "            entities = []\r\n",
                "            data_annotations = data['annotation']\r\n",
                "            if data_annotations is not None:\r\n",
                "                for annotation in data_annotations:\r\n",
                "                    point = annotation['points'][0]\r\n",
                "                    labels = annotation['label']\r\n",
                "                    if not isinstance(labels, list):\r\n",
                "                        labels = [labels]\r\n",
                "\r\n",
                "                    for label in labels:\r\n",
                "                        point_start = point['start']\r\n",
                "                        point_end = point['end']\r\n",
                "                        point_text = point['text']\r\n",
                "\r\n",
                "                        lstrip_diff = len(point_text) - \\\r\n",
                "                            len(point_text.lstrip())\r\n",
                "                        rstrip_diff = len(point_text) - \\\r\n",
                "                            len(point_text.rstrip())\r\n",
                "                        if lstrip_diff != 0:\r\n",
                "                            point_start = point_start + lstrip_diff\r\n",
                "                        if rstrip_diff != 0:\r\n",
                "                            point_end = point_end - rstrip_diff\r\n",
                "                        entities.append((point_start, point_end + 1, label))\r\n",
                "            training_data.append((text, {\"entities\": entities}))\r\n",
                "        return training_data\r\n",
                "    except Exception as e:\r\n",
                "        logging.exception(\"Unable to process \" +\r\n",
                "                          dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\r\n",
                "        return None\r\n",
                "\r\n",
                "\r\n",
                "def trim_entity_spans(data: list) -> list:\r\n",
                "    \"\"\"Removes leading and trailing white spaces from entity spans.\r\n",
                "    Args:\r\n",
                "        data (list): The data to be cleaned in spaCy JSON format.\r\n",
                "    Returns:\r\n",
                "        list: The cleaned data.\r\n",
                "    \"\"\"\r\n",
                "    invalid_span_tokens = re.compile(r'\\s')\r\n",
                "\r\n",
                "    cleaned_data = []\r\n",
                "    for text, annotations in data:\r\n",
                "        entities = annotations['entities']\r\n",
                "        valid_entities = []\r\n",
                "        for start, end, label in entities:\r\n",
                "            valid_start = start\r\n",
                "            valid_end = end\r\n",
                "            while valid_start < len(text) and invalid_span_tokens.match(\r\n",
                "                    text[valid_start]):\r\n",
                "                valid_start += 1\r\n",
                "            while valid_end > 1 and invalid_span_tokens.match(\r\n",
                "                    text[valid_end - 1]):\r\n",
                "                valid_end -= 1\r\n",
                "            valid_entities.append([valid_start, valid_end, label])\r\n",
                "        cleaned_data.append([text, {'entities': valid_entities}])\r\n",
                "    return cleaned_data\r\n",
                "\r\n",
                "\r\n",
                "def get_label(offset, labels):\r\n",
                "    if offset[0] == 0 and offset[1] == 0:\r\n",
                "        return 'O'\r\n",
                "    for label in labels:\r\n",
                "        if offset[1] >= label[0] and offset[0] <= label[1]:\r\n",
                "            return label[2]\r\n",
                "    return 'O'\r\n",
                "\r\n",
                "\r\n",
                "tags_vals = [\"UNKNOWN\", \"O\", \"Name\", \"Degree\", \"Skills\", \"College Name\", \"Email Address\",\r\n",
                "             \"Designation\", \"Companies worked at\", \"Graduation Year\", \"Years of Experience\", \"Location\"]\r\n",
                "\r\n",
                "tag2idx = {t: i for i, t in enumerate(tags_vals)}\r\n",
                "idx2tag = {i: t for i, t in enumerate(tags_vals)}\r\n",
                "\r\n",
                "\r\n",
                "def process_resume(data, tokenizer, tag2idx, max_len, is_test=False):\r\n",
                "    tok = tokenizer.encode_plus(\r\n",
                "        data[0], max_length=max_len, return_offsets_mapping=True)\r\n",
                "    curr_sent = {'orig_labels': [], 'labels': []}\r\n",
                "\r\n",
                "    padding_length = max_len - len(tok['input_ids'])\r\n",
                "\r\n",
                "    if not is_test:\r\n",
                "        labels = data[1]['entities']\r\n",
                "        labels.reverse()\r\n",
                "        for off in tok['offset_mapping']:\r\n",
                "            label = get_label(off, labels)\r\n",
                "            curr_sent['orig_labels'].append(label)\r\n",
                "            curr_sent['labels'].append(tag2idx[label])\r\n",
                "        curr_sent['labels'] = curr_sent['labels'] + ([0] * padding_length)\r\n",
                "\r\n",
                "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\r\n",
                "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\r\n",
                "        ([0] * padding_length)\r\n",
                "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\r\n",
                "        ([0] * padding_length)\r\n",
                "    return curr_sent\r\n",
                "\r\n",
                "\r\n",
                "class ResumeDataset(Dataset):\r\n",
                "    def __init__(self, resume, tokenizer, tag2idx, max_len, is_test=False):\r\n",
                "        self.resume = resume\r\n",
                "        self.tokenizer = tokenizer\r\n",
                "        self.is_test = is_test\r\n",
                "        self.tag2idx = tag2idx\r\n",
                "        self.max_len = max_len\r\n",
                "\r\n",
                "    def __len__(self):\r\n",
                "        return len(self.resume)\r\n",
                "\r\n",
                "    def __getitem__(self, idx):\r\n",
                "        data = process_resume(\r\n",
                "            self.resume[idx], self.tokenizer, self.tag2idx, self.max_len, self.is_test)\r\n",
                "        return {\r\n",
                "            'input_ids': torch.tensor(data['input_ids'], dtype=torch.long),\r\n",
                "            'token_type_ids': torch.tensor(data['token_type_ids'], dtype=torch.long),\r\n",
                "            'attention_mask': torch.tensor(data['attention_mask'], dtype=torch.long),\r\n",
                "            'labels': torch.tensor(data['labels'], dtype=torch.long),\r\n",
                "            'orig_label': data['orig_labels']\r\n",
                "        }\r\n",
                "\r\n",
                "\r\n",
                "def get_hyperparameters(model, ff):\r\n",
                "\r\n",
                "    # ff: full_finetuning\r\n",
                "    if ff:\r\n",
                "        param_optimizer = list(model.named_parameters())\r\n",
                "        no_decay = [\"bias\", \"gamma\", \"beta\"]\r\n",
                "        optimizer_grouped_parameters = [\r\n",
                "            {\r\n",
                "                \"params\": [\r\n",
                "                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\r\n",
                "                ],\r\n",
                "                \"weight_decay_rate\": 0.01,\r\n",
                "            },\r\n",
                "            {\r\n",
                "                \"params\": [\r\n",
                "                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\r\n",
                "                ],\r\n",
                "                \"weight_decay_rate\": 0.0,\r\n",
                "            },\r\n",
                "        ]\r\n",
                "    else:\r\n",
                "        param_optimizer = list(model.classifier.named_parameters())\r\n",
                "        optimizer_grouped_parameters = [\r\n",
                "            {\"params\": [p for n, p in param_optimizer]}]\r\n",
                "\r\n",
                "    return optimizer_grouped_parameters\r\n",
                "\r\n",
                "\r\n",
                "def get_special_tokens(tokenizer, tag2idx):\r\n",
                "    vocab = tokenizer.get_vocab()\r\n",
                "    pad_tok = vocab[\"[PAD]\"]\r\n",
                "    sep_tok = vocab[\"[SEP]\"]\r\n",
                "    cls_tok = vocab[\"[CLS]\"]\r\n",
                "    o_lab = tag2idx[\"O\"]\r\n",
                "\r\n",
                "    return pad_tok, sep_tok, cls_tok, o_lab\r\n",
                "\r\n",
                "\r\n",
                "def annot_confusion_matrix(valid_tags, pred_tags):\r\n",
                "    \"\"\"\r\n",
                "    Create an annotated confusion matrix by adding label\r\n",
                "    annotations and formatting to sklearn's `confusion_matrix`.\r\n",
                "    \"\"\"\r\n",
                "\r\n",
                "    header = sorted(list(set(valid_tags + pred_tags)))\r\n",
                "\r\n",
                "    matrix = confusion_matrix(valid_tags, pred_tags, labels=header)\r\n",
                "\r\n",
                "    mat_formatted = [header[i] + \"\\t\\t\\t\" +\r\n",
                "                     str(row) for i, row in enumerate(matrix)]\r\n",
                "    content = \"\\t\" + \" \".join(header) + \"\\n\" + \"\\n\".join(mat_formatted)\r\n",
                "\r\n",
                "    return content\r\n",
                "\r\n",
                "\r\n",
                "def flat_accuracy(valid_tags, pred_tags):\r\n",
                "    return (np.array(valid_tags) == np.array(pred_tags)).mean()\r\n",
                "\r\n",
                "\r\n",
                "def train_and_val_model(\r\n",
                "    model,\r\n",
                "    tokenizer,\r\n",
                "    optimizer,\r\n",
                "    epochs,\r\n",
                "    idx2tag,\r\n",
                "    tag2idx,\r\n",
                "    max_grad_norm,\r\n",
                "    device,\r\n",
                "    train_dataloader,\r\n",
                "    valid_dataloader\r\n",
                "):\r\n",
                "\r\n",
                "    pad_tok, sep_tok, cls_tok, o_lab = get_special_tokens(tokenizer, tag2idx)\r\n",
                "\r\n",
                "    epoch = 0\r\n",
                "    for _ in trange(epochs, desc=\"Epoch\"):\r\n",
                "        epoch += 1\r\n",
                "\r\n",
                "        # Training loop\r\n",
                "        print(\"Starting training loop.\")\r\n",
                "        model.train()\r\n",
                "        tr_loss, tr_accuracy = 0, 0\r\n",
                "        nb_tr_examples, nb_tr_steps = 0, 0\r\n",
                "        tr_preds, tr_labels = [], []\r\n",
                "\r\n",
                "        for step, batch in enumerate(train_dataloader):\r\n",
                "            # Add batch to gpu\r\n",
                "\r\n",
                "            # batch = tuple(t.to(device) for t in batch)\r\n",
                "            b_input_ids, b_input_mask, b_labels = batch['input_ids'], batch['attention_mask'], batch['labels']\r\n",
                "            b_input_ids, b_input_mask, b_labels = b_input_ids.to(\r\n",
                "                device), b_input_mask.to(device), b_labels.to(device)\r\n",
                "\r\n",
                "            # Forward pass\r\n",
                "            outputs = model(\r\n",
                "                b_input_ids,\r\n",
                "                token_type_ids=None,\r\n",
                "                attention_mask=b_input_mask,\r\n",
                "                labels=b_labels,\r\n",
                "            )\r\n",
                "            loss, tr_logits = outputs[:2]\r\n",
                "\r\n",
                "            # Backward pass\r\n",
                "            loss.backward()\r\n",
                "\r\n",
                "            # Compute train loss\r\n",
                "            tr_loss += loss.item()\r\n",
                "            nb_tr_examples += b_input_ids.size(0)\r\n",
                "            nb_tr_steps += 1\r\n",
                "\r\n",
                "            # Subset out unwanted predictions on CLS/PAD/SEP tokens\r\n",
                "            preds_mask = (\r\n",
                "                (b_input_ids != cls_tok)\r\n",
                "                & (b_input_ids != pad_tok)\r\n",
                "                & (b_input_ids != sep_tok)\r\n",
                "            )\r\n",
                "\r\n",
                "            tr_logits = tr_logits.cpu().detach().numpy()\r\n",
                "            tr_label_ids = torch.masked_select(b_labels, (preds_mask == 1))\r\n",
                "            preds_mask = preds_mask.cpu().detach().numpy()\r\n",
                "            tr_batch_preds = np.argmax(tr_logits[preds_mask.squeeze()], axis=1)\r\n",
                "            tr_batch_labels = tr_label_ids.to(\"cpu\").numpy()\r\n",
                "            tr_preds.extend(tr_batch_preds)\r\n",
                "            tr_labels.extend(tr_batch_labels)\r\n",
                "\r\n",
                "            # Compute training accuracy\r\n",
                "            tmp_tr_accuracy = flat_accuracy(tr_batch_labels, tr_batch_preds)\r\n",
                "            tr_accuracy += tmp_tr_accuracy\r\n",
                "\r\n",
                "            # Gradient clipping\r\n",
                "            torch.nn.utils.clip_grad_norm_(\r\n",
                "                parameters=model.parameters(), max_norm=max_grad_norm\r\n",
                "            )\r\n",
                "\r\n",
                "            # Update parameters\r\n",
                "            optimizer.step()\r\n",
                "            model.zero_grad()\r\n",
                "\r\n",
                "        tr_loss = tr_loss / nb_tr_steps\r\n",
                "        tr_accuracy = tr_accuracy / nb_tr_steps\r\n",
                "\r\n",
                "        # Print training loss and accuracy per epoch\r\n",
                "        print(f\"Train loss: {tr_loss}\")\r\n",
                "        print(f\"Train accuracy: {tr_accuracy}\")\r\n",
                "\r\n",
                "        \"\"\"\r\n",
                "        Validation loop\r\n",
                "        \"\"\"\r\n",
                "        print(\"Starting validation loop.\")\r\n",
                "\r\n",
                "        model.eval()\r\n",
                "        eval_loss, eval_accuracy = 0, 0\r\n",
                "        nb_eval_steps, nb_eval_examples = 0, 0\r\n",
                "        predictions, true_labels = [], []\r\n",
                "\r\n",
                "        for batch in valid_dataloader:\r\n",
                "\r\n",
                "            b_input_ids, b_input_mask, b_labels = batch['input_ids'], batch['attention_mask'], batch['labels']\r\n",
                "            b_input_ids, b_input_mask, b_labels = b_input_ids.to(\r\n",
                "                device), b_input_mask.to(device), b_labels.to(device)\r\n",
                "\r\n",
                "            with torch.no_grad():\r\n",
                "                outputs = model(\r\n",
                "                    b_input_ids,\r\n",
                "                    token_type_ids=None,\r\n",
                "                    attention_mask=b_input_mask,\r\n",
                "                    labels=b_labels,\r\n",
                "                )\r\n",
                "                tmp_eval_loss, logits = outputs[:2]\r\n",
                "\r\n",
                "            # Subset out unwanted predictions on CLS/PAD/SEP tokens\r\n",
                "            preds_mask = (\r\n",
                "                (b_input_ids != cls_tok)\r\n",
                "                & (b_input_ids != pad_tok)\r\n",
                "                & (b_input_ids != sep_tok)\r\n",
                "            )\r\n",
                "\r\n",
                "            logits = logits.cpu().detach().numpy()\r\n",
                "            label_ids = torch.masked_select(b_labels, (preds_mask == 1))\r\n",
                "            preds_mask = preds_mask.cpu().detach().numpy()\r\n",
                "            val_batch_preds = np.argmax(logits[preds_mask.squeeze()], axis=1)\r\n",
                "            val_batch_labels = label_ids.to(\"cpu\").numpy()\r\n",
                "            predictions.extend(val_batch_preds)\r\n",
                "            true_labels.extend(val_batch_labels)\r\n",
                "\r\n",
                "            tmp_eval_accuracy = flat_accuracy(\r\n",
                "                val_batch_labels, val_batch_preds)\r\n",
                "\r\n",
                "            eval_loss += tmp_eval_loss.mean().item()\r\n",
                "            eval_accuracy += tmp_eval_accuracy\r\n",
                "\r\n",
                "            nb_eval_examples += b_input_ids.size(0)\r\n",
                "            nb_eval_steps += 1\r\n",
                "\r\n",
                "        # Evaluate loss, acc, conf. matrix, and class. report on devset\r\n",
                "        pred_tags = [idx2tag[i] for i in predictions]\r\n",
                "        valid_tags = [idx2tag[i] for i in true_labels]\r\n",
                "        cl_report = classification_report(valid_tags, pred_tags)\r\n",
                "        conf_mat = annot_confusion_matrix(valid_tags, pred_tags)\r\n",
                "        eval_loss = eval_loss / nb_eval_steps\r\n",
                "        eval_accuracy = eval_accuracy / nb_eval_steps\r\n",
                "\r\n",
                "        # Report metrics\r\n",
                "        print(f\"Validation loss: {eval_loss}\")\r\n",
                "        print(f\"Validation Accuracy: {eval_accuracy}\")\r\n",
                "        print(f\"Classification Report:\\n {cl_report}\")\r\n",
                "        print(f\"Confusion Matrix:\\n {conf_mat}\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "import argparse\r\n",
                "import numpy as np\r\n",
                "import torch\r\n",
                "from transformers import BertForTokenClassification, BertTokenizerFast\r\n",
                "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\r\n",
                "from torch.optim import Adam\r\n",
                "#from utils import trim_entity_spans, convert_goldparse, ResumeDataset, tag2idx, idx2tag, get_hyperparameters, train_and_val_model\r\n",
                "\r\n",
                "\r\n",
                "parser = argparse.ArgumentParser(description='Train Bert-NER')\r\n",
                "parser.add_argument('-e', type=int, default=5, help='number of epochs')\r\n",
                "parser.add_argument('-o', type=str, default='.',\r\n",
                "                    help='output path to save model state')\r\n",
                "\r\n",
                "args = parser.parse_args().__dict__\r\n",
                "\r\n",
                "output_path = args['o']\r\n",
                "\r\n",
                "MAX_LEN = 500\r\n",
                "EPOCHS = args['e']\r\n",
                "MAX_GRAD_NORM = 1.0\r\n",
                "MODEL_NAME = 'bert-base-uncased'\r\n",
                "TOKENIZER = BertTokenizerFast('./vocab/vocab.txt', lowercase=True)\r\n",
                "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
                "\r\n",
                "data = trim_entity_spans(convert_goldparse(\"D:/FINAL YEAR PROJECT/Resumes/Resumes.json\"))\r\n",
                "\r\n",
                "total = len(data)\r\n",
                "train_data, val_data = data[:180], data[180:]\r\n",
                "\r\n",
                "train_d = ResumeDataset(train_data, TOKENIZER, tag2idx, MAX_LEN)\r\n",
                "val_d = ResumeDataset(val_data, TOKENIZER, tag2idx, MAX_LEN)\r\n",
                "\r\n",
                "train_sampler = RandomSampler(train_d)\r\n",
                "train_dl = DataLoader(train_d, sampler=train_sampler, batch_size=8)\r\n",
                "\r\n",
                "val_dl = DataLoader(val_d, batch_size=4)\r\n",
                "\r\n",
                "model = BertForTokenClassification.from_pretrained(\r\n",
                "    MODEL_NAME, num_labels=len(tag2idx))\r\n",
                "model.to(DEVICE)\r\n",
                "optimizer_grouped_parameters = get_hyperparameters(model, True)\r\n",
                "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\r\n",
                "\r\n",
                "train_and_val_model(\r\n",
                "    model,\r\n",
                "    TOKENIZER,\r\n",
                "    optimizer,\r\n",
                "    EPOCHS,\r\n",
                "    idx2tag,\r\n",
                "    tag2idx,\r\n",
                "    MAX_GRAD_NORM,\r\n",
                "    DEVICE,\r\n",
                "    train_dl,\r\n",
                "    val_dl\r\n",
                ")\r\n",
                "\r\n",
                "torch.save(\r\n",
                "    {\r\n",
                "        \"model_state_dict\": model.state_dict()\r\n",
                "    },\r\n",
                "    f'{output_path}/model-state.bin',\r\n",
                ")"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "usage: ipykernel_launcher.py [-h] [-e E] [-o O]\n",
                        "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"354e14ff-fc6a-45d4-a4e5-c454c9880d06\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=C:\\Users\\FAITHK~1\\AppData\\Local\\Temp\\tmp-11600tVlzGbBoywls.json\n"
                    ]
                },
                {
                    "output_type": "error",
                    "ename": "SystemExit",
                    "evalue": "2",
                    "traceback": [
                        "An exception has occurred, use %tb to see the full traceback.\n",
                        "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "import sys, fitz\r\n",
                "resume = \"D:/FINAL YEAR PROJECT/Resumes/TestData/Resume_Faith Catherine Otieno.pdf\"\r\n",
                "#fname = \"D:/FINAL YEAR PROJECT/ResumeRanking/Alice Clark CV.pdf\"\r\n",
                "doc = fitz.open(resume)\r\n",
                "resume_text = \"\"\r\n",
                "for page in doc:\r\n",
                "    resume_text = resume_text + str(page.getText())\r\n",
                "tx = \"\".join(resume_text.split(\"\\n\"))\r\n",
                "print(resume_text)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Faith Catherine Otieno\n",
                        "faithcathy12@gmail.com\n",
                        "0790517633\n",
                        "Nyeri, Kenya\n",
                        "EDUCATION\n",
                        "BSC.COMPUTER SCIENCE\n",
                        "Dedan Kimathi University of Technology\n",
                        "05/2018 -12/2021,\n",
                        "Nyeri,Kenya\n",
                        "HIGH SCHOOL\n",
                        "Moi Girls Isinya\n",
                        "02/2014 - 11/2017\n",
                        "Kajiado, Kenya\n",
                        "Grade\n",
                        "B+\n",
                        "TECHNICAL SKILLS\n",
                        "\n",
                        "WEB DEVELOPMENT\n",
                        "HTML, CSS, JAVASCRIPT, BOOTSTRAP, ANGULAR, DJANGO\n",
                        "\n",
                        "PYTHON\n",
                        "General python knowledge\n",
                        "DJANGO,\n",
                        "Learning to build REST APIs,\n",
                        "Learning Machine Learning.\n",
                        "\n",
                        "JAVA\n",
                        "General Java knowledge.\n",
                        "\n",
                        "Wordpress\n",
                        "Creating websites using wordpress.\n",
                        "SOFT SKILLS\n",
                        "\n",
                        "Good communication skills.\n",
                        "\n",
                        "Skills in creating innovative solutions.\n",
                        "\n",
                        "Team player\n",
                        "ACHIEVEMENTS\n",
                        "Completed the Web Specialist program 2020 for google Africa\n",
                        "Scholarships\n",
                        "(06/2020 - 10/2020)\n",
                        "The Google Africa Scholarship is a learning base program for individuals. I\n",
                        "personally went through the Web Specialist program where I was\n",
                        "introduced to web development. The program was in phases and only a\n",
                        "number of people proceeded to the next phase through qualifications in\n",
                        "quizzes and learning time. Through the program I was able to work in a\n",
                        "team in building a project EduShare that would be beneficial to the\n",
                        "community.\n",
                        "PROJECTS\n",
                        "Github Profile\n",
                        "https://github.com/faithkatherine\n",
                        "Weather App\n",
                        "https://myweather-fc2c3.web.app/\n",
                        "Edushare\n",
                        "(10/2020 - Present)\n",
                        "A community project we did with my GADS2020 team that connects\n",
                        "students and teachers around the world for online learning through sharing\n",
                        "notes, tutorials and quizzes\n",
                        "VOLUNTEER EXPERIENCE\n",
                        "Facilitating meet ups\n",
                        "Women Tech Makers Nyeri\n",
                        "Nyeri, Kenya\n",
                        "Tasks/Achievements\n",
                        "\n",
                        "Writing letters to secure venues\n",
                        "\n",
                        "Looking for speakers.\n",
                        "\n",
                        "Working with other volunteers to create a good experience for the\n",
                        "attendees.\n",
                        "Contact:\n",
                        "Grace Kahinga\n",
                        "+254798634840\n",
                        "Organizing Events\n",
                        "Google Developer Group Nyeri\n",
                        "Nyeri, Kenya\n",
                        "Tasks/Achievements\n",
                        "Participated in the event organization of DevFest Nyeri.\n",
                        "INTERESTS\n",
                        "\n",
                        "Interested in Web Development\n",
                        "\n",
                        "Aspiring Machine Learning Engineer\n",
                        "\n",
                        "Python\n",
                        "REFERENCES\n",
                        "Abednego Ng'ang'a\n",
                        "“Mentor”\n",
                        "Contact\n",
                        ":\n",
                        "abedy.nganga@gmail.com\n",
                        "-\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "import spacy\r\n",
                "\r\n",
                "nlp = spacy.load(\"en_core_web_sm\")\r\n",
                "doc = nlp(resume_text)\r\n",
                "for token in doc:\r\n",
                "    print(token.text)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Faith\n",
                        "Catherine\n",
                        "Otieno\n",
                        "\n",
                        "\n",
                        "faithcathy12@gmail.com\n",
                        "\n",
                        "\n",
                        "0790517633\n",
                        "\n",
                        "\n",
                        "Nyeri\n",
                        ",\n",
                        "Kenya\n",
                        "\n",
                        "\n",
                        "EDUCATION\n",
                        "\n",
                        "\n",
                        "BSC.COMPUTER\n",
                        "SCIENCE\n",
                        "\n",
                        "\n",
                        "Dedan\n",
                        "Kimathi\n",
                        "University\n",
                        "of\n",
                        "Technology\n",
                        "\n",
                        "\n",
                        "05/2018\n",
                        "-12/2021\n",
                        ",\n",
                        "\n",
                        "\n",
                        "Nyeri\n",
                        ",\n",
                        "Kenya\n",
                        "\n",
                        "\n",
                        "HIGH\n",
                        "SCHOOL\n",
                        "\n",
                        "\n",
                        "Moi\n",
                        "Girls\n",
                        "Isinya\n",
                        "\n",
                        "\n",
                        "02/2014\n",
                        "-\n",
                        "11/2017\n",
                        "\n",
                        "\n",
                        "Kajiado\n",
                        ",\n",
                        "Kenya\n",
                        "\n",
                        "\n",
                        "Grade\n",
                        "\n",
                        "\n",
                        "B+\n",
                        "\n",
                        "\n",
                        "TECHNICAL\n",
                        "SKILLS\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "WEB\n",
                        "DEVELOPMENT\n",
                        "\n",
                        "\n",
                        "HTML\n",
                        ",\n",
                        "CSS\n",
                        ",\n",
                        "JAVASCRIPT\n",
                        ",\n",
                        "BOOTSTRAP\n",
                        ",\n",
                        "ANGULAR\n",
                        ",\n",
                        "DJANGO\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "PYTHON\n",
                        "\n",
                        "\n",
                        "General\n",
                        "python\n",
                        "knowledge\n",
                        "\n",
                        "\n",
                        "DJANGO\n",
                        ",\n",
                        "\n",
                        "\n",
                        "Learning\n",
                        "to\n",
                        "build\n",
                        "REST\n",
                        "APIs\n",
                        ",\n",
                        "\n",
                        "\n",
                        "Learning\n",
                        "Machine\n",
                        "Learning\n",
                        ".\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "JAVA\n",
                        "\n",
                        "\n",
                        "General\n",
                        "Java\n",
                        "knowledge\n",
                        ".\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Wordpress\n",
                        "\n",
                        "\n",
                        "Creating\n",
                        "websites\n",
                        "using\n",
                        "wordpress\n",
                        ".\n",
                        "\n",
                        "\n",
                        "SOFT\n",
                        "SKILLS\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Good\n",
                        "communication\n",
                        "skills\n",
                        ".\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Skills\n",
                        "in\n",
                        "creating\n",
                        "innovative\n",
                        "solutions\n",
                        ".\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Team\n",
                        "player\n",
                        "\n",
                        "\n",
                        "ACHIEVEMENTS\n",
                        "\n",
                        "\n",
                        "Completed\n",
                        "the\n",
                        "Web\n",
                        "Specialist\n",
                        "program\n",
                        "2020\n",
                        "for\n",
                        "google\n",
                        "Africa\n",
                        "\n",
                        "\n",
                        "Scholarships\n",
                        "\n",
                        "\n",
                        "(\n",
                        "06/2020\n",
                        "-\n",
                        "10/2020\n",
                        ")\n",
                        "\n",
                        "\n",
                        "The\n",
                        "Google\n",
                        "Africa\n",
                        "Scholarship\n",
                        "is\n",
                        "a\n",
                        "learning\n",
                        "base\n",
                        "program\n",
                        "for\n",
                        "individuals\n",
                        ".\n",
                        "I\n",
                        "\n",
                        "\n",
                        "personally\n",
                        "went\n",
                        "through\n",
                        "the\n",
                        "Web\n",
                        "Specialist\n",
                        "program\n",
                        "where\n",
                        "I\n",
                        "was\n",
                        "\n",
                        "\n",
                        "introduced\n",
                        "to\n",
                        "web\n",
                        "development\n",
                        ".\n",
                        "The\n",
                        "program\n",
                        "was\n",
                        "in\n",
                        "phases\n",
                        "and\n",
                        "only\n",
                        "a\n",
                        "\n",
                        "\n",
                        "number\n",
                        "of\n",
                        "people\n",
                        "proceeded\n",
                        "to\n",
                        "the\n",
                        "next\n",
                        "phase\n",
                        "through\n",
                        "qualifications\n",
                        "in\n",
                        "\n",
                        "\n",
                        "quizzes\n",
                        "and\n",
                        "learning\n",
                        "time\n",
                        ".\n",
                        "Through\n",
                        "the\n",
                        "program\n",
                        "I\n",
                        "was\n",
                        "able\n",
                        "to\n",
                        "work\n",
                        "in\n",
                        "a\n",
                        "\n",
                        "\n",
                        "team\n",
                        "in\n",
                        "building\n",
                        "a\n",
                        "project\n",
                        "EduShare\n",
                        "that\n",
                        "would\n",
                        "be\n",
                        "beneficial\n",
                        "to\n",
                        "the\n",
                        "\n",
                        "\n",
                        "community\n",
                        ".\n",
                        "\n",
                        "\n",
                        "PROJECTS\n",
                        "\n",
                        "\n",
                        "Github\n",
                        "Profile\n",
                        "\n",
                        "\n",
                        "https://github.com/faithkatherine\n",
                        "\n",
                        "\n",
                        "Weather\n",
                        "App\n",
                        "\n",
                        "\n",
                        "https://myweather-fc2c3.web.app/\n",
                        "\n",
                        "\n",
                        "Edushare\n",
                        "\n",
                        "\n",
                        "(\n",
                        "10/2020\n",
                        "-\n",
                        "Present\n",
                        ")\n",
                        "\n",
                        "\n",
                        "A\n",
                        "community\n",
                        "project\n",
                        "we\n",
                        "did\n",
                        "with\n",
                        "my\n",
                        "GADS2020\n",
                        "team\n",
                        "that\n",
                        "connects\n",
                        "\n",
                        "\n",
                        "students\n",
                        "and\n",
                        "teachers\n",
                        "around\n",
                        "the\n",
                        "world\n",
                        "for\n",
                        "online\n",
                        "learning\n",
                        "through\n",
                        "sharing\n",
                        "\n",
                        "\n",
                        "notes\n",
                        ",\n",
                        "tutorials\n",
                        "and\n",
                        "quizzes\n",
                        "\n",
                        "\n",
                        "VOLUNTEER\n",
                        "EXPERIENCE\n",
                        "\n",
                        "\n",
                        "Facilitating\n",
                        "meet\n",
                        "ups\n",
                        "\n",
                        "\n",
                        "Women\n",
                        "Tech\n",
                        "Makers\n",
                        "Nyeri\n",
                        "\n",
                        "\n",
                        "Nyeri\n",
                        ",\n",
                        "Kenya\n",
                        "\n",
                        "\n",
                        "Tasks\n",
                        "/\n",
                        "Achievements\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Writing\n",
                        "letters\n",
                        "to\n",
                        "secure\n",
                        "venues\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Looking\n",
                        "for\n",
                        "speakers\n",
                        ".\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Working\n",
                        "with\n",
                        "other\n",
                        "volunteers\n",
                        "to\n",
                        "create\n",
                        "a\n",
                        "good\n",
                        "experience\n",
                        "for\n",
                        "the\n",
                        "\n",
                        "\n",
                        "attendees\n",
                        ".\n",
                        "\n",
                        "\n",
                        "Contact\n",
                        ":\n",
                        "\n",
                        "\n",
                        "Grace\n",
                        "Kahinga\n",
                        "\n",
                        "\n",
                        "+254798634840\n",
                        "\n",
                        "\n",
                        "Organizing\n",
                        "Events\n",
                        "\n",
                        "\n",
                        "Google\n",
                        "Developer\n",
                        "Group\n",
                        "Nyeri\n",
                        "\n",
                        "\n",
                        "Nyeri\n",
                        ",\n",
                        "Kenya\n",
                        "\n",
                        "\n",
                        "Tasks\n",
                        "/\n",
                        "Achievements\n",
                        "\n",
                        "\n",
                        "Participated\n",
                        "in\n",
                        "the\n",
                        "event\n",
                        "organization\n",
                        "of\n",
                        "DevFest\n",
                        "Nyeri\n",
                        ".\n",
                        "\n",
                        "\n",
                        "INTERESTS\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Interested\n",
                        "in\n",
                        "Web\n",
                        "Development\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Aspiring\n",
                        "Machine\n",
                        "Learning\n",
                        "Engineer\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "\n",
                        "Python\n",
                        "\n",
                        "\n",
                        "REFERENCES\n",
                        "\n",
                        "\n",
                        "Abednego\n",
                        "Ng'ang'a\n",
                        "\n",
                        "\n",
                        "“\n",
                        "Mentor\n",
                        "”\n",
                        "\n",
                        "\n",
                        "Contact\n",
                        "\n",
                        "\n",
                        ":\n",
                        "\n",
                        "\n",
                        "abedy.nganga@gmail.com\n",
                        "\n",
                        "\n",
                        "-\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import sys, fitz\r\n",
                "resume = \"D:/FINAL YEAR PROJECT/Resumes/TestData/Resume_Faith Catherine Otieno.pdf\"\r\n",
                "#fname = \"D:/FINAL YEAR PROJECT/ResumeRanking/Alice Clark CV.pdf\"\r\n",
                "doc = fitz.open(resume)\r\n",
                "resume_text = \"\"\r\n",
                "for page in doc:\r\n",
                "    resume_text = resume_text + str(page.getText())\r\n",
                "tx = \"\".join(resume_text.split(\"\\n\"))\r\n",
                "print(resume_text)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Faith Catherine Otieno\n",
                        "faithcathy12@gmail.com\n",
                        "0790517633\n",
                        "Nyeri, Kenya\n",
                        "EDUCATION\n",
                        "BSC.COMPUTER SCIENCE\n",
                        "Dedan Kimathi University of Technology\n",
                        "05/2018 -12/2021,\n",
                        "Nyeri,Kenya\n",
                        "HIGH SCHOOL\n",
                        "Moi Girls Isinya\n",
                        "02/2014 - 11/2017\n",
                        "Kajiado, Kenya\n",
                        "Grade\n",
                        "B+\n",
                        "TECHNICAL SKILLS\n",
                        "\n",
                        "WEB DEVELOPMENT\n",
                        "HTML, CSS, JAVASCRIPT, BOOTSTRAP, ANGULAR, DJANGO\n",
                        "\n",
                        "PYTHON\n",
                        "General python knowledge\n",
                        "DJANGO,\n",
                        "Learning to build REST APIs,\n",
                        "Learning Machine Learning.\n",
                        "\n",
                        "JAVA\n",
                        "General Java knowledge.\n",
                        "\n",
                        "Wordpress\n",
                        "Creating websites using wordpress.\n",
                        "SOFT SKILLS\n",
                        "\n",
                        "Good communication skills.\n",
                        "\n",
                        "Skills in creating innovative solutions.\n",
                        "\n",
                        "Team player\n",
                        "ACHIEVEMENTS\n",
                        "Completed the Web Specialist program 2020 for google Africa\n",
                        "Scholarships\n",
                        "(06/2020 - 10/2020)\n",
                        "The Google Africa Scholarship is a learning base program for individuals. I\n",
                        "personally went through the Web Specialist program where I was\n",
                        "introduced to web development. The program was in phases and only a\n",
                        "number of people proceeded to the next phase through qualifications in\n",
                        "quizzes and learning time. Through the program I was able to work in a\n",
                        "team in building a project EduShare that would be beneficial to the\n",
                        "community.\n",
                        "PROJECTS\n",
                        "Github Profile\n",
                        "https://github.com/faithkatherine\n",
                        "Weather App\n",
                        "https://myweather-fc2c3.web.app/\n",
                        "Edushare\n",
                        "(10/2020 - Present)\n",
                        "A community project we did with my GADS2020 team that connects\n",
                        "students and teachers around the world for online learning through sharing\n",
                        "notes, tutorials and quizzes\n",
                        "VOLUNTEER EXPERIENCE\n",
                        "Facilitating meet ups\n",
                        "Women Tech Makers Nyeri\n",
                        "Nyeri, Kenya\n",
                        "Tasks/Achievements\n",
                        "\n",
                        "Writing letters to secure venues\n",
                        "\n",
                        "Looking for speakers.\n",
                        "\n",
                        "Working with other volunteers to create a good experience for the\n",
                        "attendees.\n",
                        "Contact:\n",
                        "Grace Kahinga\n",
                        "+254798634840\n",
                        "Organizing Events\n",
                        "Google Developer Group Nyeri\n",
                        "Nyeri, Kenya\n",
                        "Tasks/Achievements\n",
                        "Participated in the event organization of DevFest Nyeri.\n",
                        "INTERESTS\n",
                        "\n",
                        "Interested in Web Development\n",
                        "\n",
                        "Aspiring Machine Learning Engineer\n",
                        "\n",
                        "Python\n",
                        "REFERENCES\n",
                        "Abednego Ng'ang'a\n",
                        "“Mentor”\n",
                        "Contact\n",
                        ":\n",
                        "abedy.nganga@gmail.com\n",
                        "-\n",
                        "\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "from resume_parser import resumeparse\r\n",
                "data = resumeparse.read_file('D:/FINAL YEAR PROJECT/Resumes/TestData/Resume_Faith Catherine Otieno.pdf')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "C:\\Users\\FAITH KATHERINE\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
                        "  warnings.warn(warn_msg)\n",
                        "2021-09-14 09:18:50,721 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
                        "2021-09-14 09:18:56,248 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
                        "2021-09-14 09:19:01,249 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
                        "2021-09-14 09:19:06,251 [MainThread  ] [ERROR]  Tika startup log message not received after 3 tries.\n",
                        "2021-09-14 09:19:06,252 [MainThread  ] [ERROR]  Failed to receive startup confirmation from startServer.\n",
                        "ERROR:root:Error in tika installation:: Unable to start Tika server.\n",
                        "ERROR:root:--------------------------\n",
                        "ERROR:root:Install java for better result \n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "from spacy import displacy\r\n",
                "doc = nlp(data)\r\n",
                "displacy.render(doc, style=\"ent\")"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "TypeError",
                    "evalue": "Argument 'string' has incorrect type (expected str, got dict)",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-9-942f489b3c02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ent\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;31m#call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    465\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             )\n\u001b[1;32m--> 467\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_format_docs_and_golds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got dict)"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import spacy\r\n",
                "from spacy.matcher import PhraseMatcher\r\n",
                "\r\n",
                "nlp = spacy.load(\"en_core_web_sm\")\r\n",
                "matcher = PhraseMatcher(nlp.vocab)\r\n",
                "terms = [\"Grade B+\", \"Grade A\", \"Grade A-\" ]\r\n",
                "# Only run nlp.make_doc to speed things up\r\n",
                "patterns = [nlp.make_doc(text) for text in terms]\r\n",
                "matcher.add(\"TerminologyList\", patterns)\r\n",
                "\r\n",
                "doc = nlp(resume_text)\r\n",
                "matches = matcher(doc)\r\n",
                "for match_id, start, end in matches:\r\n",
                "    span = doc[start:end]\r\n",
                "    print(span.text)"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'resume_text' is not defined",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m<ipython-input-1-ddd09168868b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TerminologyList\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmatch_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'resume_text' is not defined"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "kernelspec": {
            "name": ".venv",
            "display_name": ".venv",
            "language": "python"
        },
        "interpreter": {
            "hash": "83c81250742688ff467ca0520eff071d3643ef1d2af42510597b728483f832c8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}